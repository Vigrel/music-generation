{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53292e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import (Activation, BatchNormalization, Dense,\n",
    "                                     Dropout, Flatten, Input, Reshape,\n",
    "                                     TimeDistributed)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "260e61e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d72d9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31ccf1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 250\n",
    "LR = 0.001\n",
    "WRITE_HISTORY = True\n",
    "NUM_RAND_SONGS = 10\n",
    "DO_RATE = 0.1\n",
    "BN_M = 0.9\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "MAX_LENGTH = 16\n",
    "PARAM_SIZE = 120\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d014c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_samples = np.load('samples.npy')\n",
    "y_lengths = np.load('lengths.npy')\n",
    "num_songs = y_lengths.shape[0]\n",
    "\n",
    "y_shape = (num_songs, MAX_LENGTH) + y_samples.shape[1:]\n",
    "y_orig = np.zeros(y_shape, dtype=y_samples.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc293842",
   "metadata": {},
   "source": [
    "* y_samples = (_, 96, 96)\n",
    "* y_lengths = (238,)  cada elemento qnts ticks tem a musica\n",
    "* y_shape = (238, 16, 96, 96)\n",
    "* y_origin = Array de zeros (238, 16, 96, 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85096883",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_ix = 0\n",
    "for i in range(num_songs):\n",
    "    end_ix = cur_ix + y_lengths[i]\n",
    "    for j in range(MAX_LENGTH):\n",
    "        k = j % (end_ix - cur_ix) \n",
    "        y_orig[i,j] = y_samples[cur_ix + k]\n",
    "    cur_ix = end_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d939754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.copy(y_orig)\n",
    "\n",
    "y_train = y[:125]\n",
    "y_valid = y[125:]\n",
    "\n",
    "y_test_song = np.copy(y[0])\n",
    "midi.samples_to_midi(y_test_song, 'gt.mid', 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9091b0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\eller\\anaconda3\\envs\\IC\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py:520: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "x_in = Input(shape=y_shape[1:])\n",
    "x = Reshape((y_shape[1], -1))(x_in)\n",
    "x = TimeDistributed(Dense(2000, activation='relu'))(x)\n",
    "x = TimeDistributed(Dense(200, activation='relu'))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(1600, activation='relu')(x)\n",
    "x = Dense(PARAM_SIZE)(x)\n",
    "x = BatchNormalization(momentum=BN_M, name='pre_encoder')(x)\n",
    "x = Dense(1600, name='encoder')(x)\n",
    "x = BatchNormalization(momentum=BN_M)(x)\n",
    "x = Activation('relu')(x)\n",
    "if DO_RATE > 0:\n",
    "    x = Dropout(DO_RATE)(x)\n",
    "x = Dense(MAX_LENGTH * 200)(x)\n",
    "x = Reshape((MAX_LENGTH, 200))(x)\n",
    "x = TimeDistributed(BatchNormalization(momentum=BN_M))(x)\n",
    "x = Activation('relu')(x)\n",
    "if DO_RATE > 0:\n",
    "    x = Dropout(DO_RATE)(x)\n",
    "x = TimeDistributed(Dense(2000))(x)\n",
    "x = TimeDistributed(BatchNormalization(momentum=BN_M))(x)\n",
    "x = Activation('relu')(x)\n",
    "if DO_RATE > 0:\n",
    "    x = Dropout(DO_RATE)(x)\n",
    "x = TimeDistributed(Dense(y_shape[2] * y_shape[3], activation='sigmoid'))(x)\n",
    "x = Reshape((y_shape[1], y_shape[2], y_shape[3]))(x)\n",
    "\n",
    "model = Model(x_in, x)\n",
    "model.compile(optimizer=RMSprop(learning_rate=LR), loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9c9bae11",
   "metadata": {},
   "outputs": [],
   "source": [
    "func = K.function([model.get_layer('encoder').input, K.learning_phase()], [model.layers[-1].output])\n",
    "enc = Model(inputs=model.input, outputs=model.get_layer('pre_encoder').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "617f7bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_vecs = np.random.normal(0.0, 1.0, (NUM_RAND_SONGS, PARAM_SIZE))\n",
    "np.save('rand.npy', rand_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f0ea159d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rand_songs(write_dir, rand_vecs):\n",
    "    for i in range(rand_vecs.shape[0]):\n",
    "        x_rand = rand_vecs[i:i+1]\n",
    "        y_song = func([x_rand, 0])[0]\n",
    "        midi.samples_to_midi(y_song[0], write_dir + 'rand' + str(i) + '.mid', 16, 0.25)\n",
    "\n",
    "def make_rand_songs_normalized(write_dir, rand_vecs):\n",
    "    x_enc = np.squeeze(enc.predict(y_orig))\n",
    "\n",
    "    x_mean = np.mean(x_enc, axis=0)\n",
    "    x_cov = np.cov((x_enc - x_mean).T)\n",
    "    _, s, v = np.linalg.svd(x_cov)\n",
    "    e = np.sqrt(s)\n",
    "\n",
    "    print(f\"Means: {x_mean[:6]}\")\n",
    "    print(f\"Evals: {e[:6]} \")\n",
    "\n",
    "    x_vecs = x_mean + np.dot(rand_vecs * e, v)\n",
    "    make_rand_songs(write_dir, x_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0d54af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(\n",
    "    \"logs\",\n",
    "    datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
    ")\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=log_dir),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcdbae28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model():\n",
    "#     def rounded_accuracy(y_true, y_pred):\n",
    "#         return tf.keras.metrics.binary_accuracy(\n",
    "#             tf.round(y_true),\n",
    "#             tf.round(y_pred),\n",
    "#         )\n",
    "    \n",
    "#     stacked_encoder = tf.keras.models.Sequential([\n",
    "#         Input(shape=(16,96,96)),\n",
    "#         Reshape((16, -1)),\n",
    "#         TimeDistributed(Dense(2000, activation='relu')),\n",
    "#         TimeDistributed(Dense(200, activation='relu')),\n",
    "#         Flatten(),\n",
    "#         Dense(1600, activation='relu'),\n",
    "#         Dense(PARAM_SIZE),\n",
    "#         BatchNormalization(momentum=BN_M, name='pre_encoder')\n",
    "#     ])\n",
    "#     stacked_decoder = tf.keras.models.Sequential([\n",
    "#         Dense(1600, name='encoder'),\n",
    "#         BatchNormalization(momentum=BN_M),\n",
    "#         Activation('relu'),\n",
    "#         Dense(MAX_LENGTH * 200),\n",
    "#         Reshape((MAX_LENGTH, 200)),\n",
    "#         TimeDistributed(BatchNormalization(momentum=BN_M)),\n",
    "#         Activation('relu'),\n",
    "#         TimeDistributed(Dense(2000)),\n",
    "#         TimeDistributed(BatchNormalization(momentum=BN_M)),\n",
    "#         Activation('relu'),\n",
    "#         TimeDistributed(Dense(96 * 96, activation='sigmoid')),\n",
    "#         Reshape((16,96,96))\n",
    "#     ])\n",
    "#     stacked_ae = tf.keras.models.Sequential([stacked_encoder, stacked_decoder])\n",
    "\n",
    "#     stacked_ae.compile(\n",
    "#         loss=\"binary_crossentropy\",\n",
    "#         optimizer= RMSprop(learning_rate=LR),\n",
    "#         metrics=[rounded_accuracy],\n",
    "#     )\n",
    "\n",
    "#     return stacked_encoder, stacked_decoder, stacked_ae\n",
    "\n",
    "# stacked_encoder, stacked_decoder, model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2eb91f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 125 samples, validate on 113 samples\n",
      "Epoch 1/250\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eller\\anaconda3\\envs\\IC\\lib\\site-packages\\keras\\engine\\training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 - 3s - loss: 0.7160 - val_loss: 0.6530\n",
      "Epoch 2/250\n",
      "125/125 - 0s - loss: 0.2119 - val_loss: 0.6078\n",
      "Epoch 3/250\n",
      "125/125 - 0s - loss: 0.0696 - val_loss: 0.4969\n",
      "Epoch 4/250\n",
      "125/125 - 0s - loss: 0.0715 - val_loss: 0.4553\n",
      "Epoch 5/250\n",
      "125/125 - 0s - loss: 0.0478 - val_loss: 0.3783\n",
      "Epoch 6/250\n",
      "125/125 - 0s - loss: 0.0350 - val_loss: 0.3641\n",
      "Epoch 7/250\n",
      "125/125 - 0s - loss: 0.0304 - val_loss: 0.3242\n",
      "Epoch 8/250\n",
      "125/125 - 0s - loss: 0.0278 - val_loss: 0.3126\n",
      "Epoch 9/250\n",
      "125/125 - 0s - loss: 0.0259 - val_loss: 0.2616\n",
      "Epoch 10/250\n",
      "125/125 - 0s - loss: 0.0245 - val_loss: 0.2552\n",
      "Epoch 11/250\n",
      "125/125 - 0s - loss: 0.0234 - val_loss: 0.2043\n",
      "Epoch 12/250\n",
      "125/125 - 0s - loss: 0.0224 - val_loss: 0.1974\n",
      "Epoch 13/250\n",
      "125/125 - 0s - loss: 0.0217 - val_loss: 0.1612\n",
      "Epoch 14/250\n",
      "125/125 - 0s - loss: 0.0210 - val_loss: 0.1476\n",
      "Epoch 15/250\n",
      "125/125 - 0s - loss: 0.0204 - val_loss: 0.1255\n",
      "Epoch 16/250\n",
      "125/125 - 0s - loss: 0.0200 - val_loss: 0.1122\n",
      "Epoch 17/250\n",
      "125/125 - 0s - loss: 0.0195 - val_loss: 0.0957\n",
      "Epoch 18/250\n",
      "125/125 - 0s - loss: 0.0191 - val_loss: 0.0857\n",
      "Epoch 19/250\n",
      "125/125 - 0s - loss: 0.0188 - val_loss: 0.0737\n",
      "Epoch 20/250\n",
      "125/125 - 0s - loss: 0.0185 - val_loss: 0.0663\n",
      "Epoch 21/250\n",
      "125/125 - 0s - loss: 0.0183 - val_loss: 0.0575\n",
      "Epoch 22/250\n",
      "125/125 - 0s - loss: 0.0180 - val_loss: 0.0537\n",
      "Epoch 23/250\n",
      "125/125 - 0s - loss: 0.0178 - val_loss: 0.0472\n",
      "Epoch 24/250\n",
      "125/125 - 0s - loss: 0.0176 - val_loss: 0.0432\n",
      "Epoch 25/250\n",
      "125/125 - 0s - loss: 0.0174 - val_loss: 0.0395\n",
      "Epoch 26/250\n",
      "125/125 - 0s - loss: 0.0172 - val_loss: 0.0365\n",
      "Epoch 27/250\n",
      "125/125 - 0s - loss: 0.0171 - val_loss: 0.0337\n",
      "Epoch 28/250\n",
      "125/125 - 0s - loss: 0.0169 - val_loss: 0.0322\n",
      "Epoch 29/250\n",
      "125/125 - 0s - loss: 0.0168 - val_loss: 0.0299\n",
      "Epoch 30/250\n",
      "125/125 - 0s - loss: 0.0167 - val_loss: 0.0292\n",
      "Epoch 31/250\n",
      "125/125 - 0s - loss: 0.0166 - val_loss: 0.0259\n",
      "Epoch 32/250\n",
      "125/125 - 0s - loss: 0.0164 - val_loss: 0.0270\n",
      "Epoch 33/250\n",
      "125/125 - 0s - loss: 0.0163 - val_loss: 0.0241\n",
      "Epoch 34/250\n",
      "125/125 - 0s - loss: 0.0163 - val_loss: 0.0253\n",
      "Epoch 35/250\n",
      "125/125 - 0s - loss: 0.0161 - val_loss: 0.0219\n",
      "Epoch 36/250\n",
      "125/125 - 0s - loss: 0.0161 - val_loss: 0.0228\n",
      "Epoch 37/250\n",
      "125/125 - 0s - loss: 0.0160 - val_loss: 0.0203\n",
      "Epoch 38/250\n",
      "125/125 - 0s - loss: 0.0159 - val_loss: 0.0232\n",
      "Epoch 39/250\n",
      "125/125 - 0s - loss: 0.0159 - val_loss: 0.0205\n",
      "Epoch 40/250\n",
      "125/125 - 0s - loss: 0.0159 - val_loss: 0.0213\n",
      "Epoch 41/250\n",
      "125/125 - 0s - loss: 0.0158 - val_loss: 0.0211\n",
      "Epoch 42/250\n",
      "125/125 - 0s - loss: 0.0157 - val_loss: 0.0220\n",
      "Epoch 43/250\n",
      "125/125 - 0s - loss: 0.0155 - val_loss: 0.0208\n",
      "Epoch 44/250\n",
      "125/125 - 0s - loss: 0.0155 - val_loss: 0.0227\n",
      "Epoch 45/250\n",
      "125/125 - 0s - loss: 0.0153 - val_loss: 0.0209\n",
      "Epoch 46/250\n",
      "125/125 - 0s - loss: 0.0153 - val_loss: 0.0225\n",
      "Epoch 47/250\n",
      "125/125 - 0s - loss: 0.0151 - val_loss: 0.0205\n",
      "Epoch 48/250\n",
      "125/125 - 0s - loss: 0.0151 - val_loss: 0.0217\n",
      "Epoch 49/250\n",
      "125/125 - 0s - loss: 0.0149 - val_loss: 0.0202\n",
      "Epoch 50/250\n",
      "125/125 - 0s - loss: 0.0150 - val_loss: 0.0202\n",
      "Epoch 51/250\n",
      "125/125 - 0s - loss: 0.0148 - val_loss: 0.0197\n",
      "Epoch 52/250\n",
      "125/125 - 0s - loss: 0.0148 - val_loss: 0.0202\n",
      "Epoch 53/250\n",
      "125/125 - 0s - loss: 0.0146 - val_loss: 0.0198\n",
      "Epoch 54/250\n",
      "125/125 - 0s - loss: 0.0147 - val_loss: 0.0199\n",
      "Epoch 55/250\n",
      "125/125 - 0s - loss: 0.0145 - val_loss: 0.0198\n",
      "Epoch 56/250\n",
      "125/125 - 0s - loss: 0.0145 - val_loss: 0.0200\n",
      "Epoch 57/250\n",
      "125/125 - 0s - loss: 0.0143 - val_loss: 0.0197\n",
      "Epoch 58/250\n",
      "125/125 - 0s - loss: 0.0144 - val_loss: 0.0199\n",
      "Epoch 59/250\n",
      "125/125 - 0s - loss: 0.0142 - val_loss: 0.0198\n",
      "Epoch 60/250\n",
      "125/125 - 0s - loss: 0.0142 - val_loss: 0.0193\n",
      "Epoch 61/250\n",
      "125/125 - 0s - loss: 0.0138 - val_loss: 0.0195\n",
      "Epoch 62/250\n",
      "125/125 - 0s - loss: 0.0139 - val_loss: 0.0193\n",
      "Epoch 63/250\n",
      "125/125 - 0s - loss: 0.0135 - val_loss: 0.0197\n",
      "Epoch 64/250\n",
      "125/125 - 0s - loss: 0.0136 - val_loss: 0.0203\n",
      "Epoch 65/250\n",
      "125/125 - 0s - loss: 0.0134 - val_loss: 0.0192\n",
      "Epoch 66/250\n",
      "125/125 - 0s - loss: 0.0133 - val_loss: 0.0195\n",
      "Epoch 67/250\n",
      "125/125 - 0s - loss: 0.0131 - val_loss: 0.0194\n",
      "Epoch 68/250\n",
      "125/125 - 0s - loss: 0.0128 - val_loss: 0.0193\n",
      "Epoch 69/250\n",
      "125/125 - 0s - loss: 0.0126 - val_loss: 0.0196\n",
      "Epoch 70/250\n",
      "125/125 - 0s - loss: 0.0124 - val_loss: 0.0192\n",
      "Epoch 71/250\n",
      "125/125 - 0s - loss: 0.0124 - val_loss: 0.0198\n",
      "Epoch 72/250\n",
      "125/125 - 0s - loss: 0.0123 - val_loss: 0.0193\n",
      "Epoch 73/250\n",
      "125/125 - 0s - loss: 0.0122 - val_loss: 0.0193\n",
      "Epoch 74/250\n",
      "125/125 - 0s - loss: 0.0121 - val_loss: 0.0196\n",
      "Epoch 75/250\n",
      "125/125 - 0s - loss: 0.0120 - val_loss: 0.0198\n",
      "Epoch 76/250\n",
      "125/125 - 0s - loss: 0.0118 - val_loss: 0.0201\n",
      "Epoch 77/250\n",
      "125/125 - 0s - loss: 0.0117 - val_loss: 0.0195\n",
      "Epoch 78/250\n",
      "125/125 - 0s - loss: 0.0114 - val_loss: 0.0201\n",
      "Epoch 79/250\n",
      "125/125 - 0s - loss: 0.0114 - val_loss: 0.0194\n",
      "Epoch 80/250\n",
      "125/125 - 0s - loss: 0.0111 - val_loss: 0.0195\n",
      "Epoch 81/250\n",
      "125/125 - 0s - loss: 0.0109 - val_loss: 0.0185\n",
      "Epoch 82/250\n",
      "125/125 - 0s - loss: 0.0103 - val_loss: 0.0197\n",
      "Epoch 83/250\n",
      "125/125 - 0s - loss: 0.0104 - val_loss: 0.0202\n",
      "Epoch 84/250\n",
      "125/125 - 0s - loss: 0.0104 - val_loss: 0.0205\n",
      "Epoch 85/250\n",
      "125/125 - 0s - loss: 0.0103 - val_loss: 0.0190\n",
      "Epoch 86/250\n",
      "125/125 - 0s - loss: 0.0097 - val_loss: 0.0191\n",
      "Epoch 87/250\n",
      "125/125 - 0s - loss: 0.0096 - val_loss: 0.0184\n",
      "Epoch 88/250\n",
      "125/125 - 0s - loss: 0.0093 - val_loss: 0.0194\n",
      "Epoch 89/250\n",
      "125/125 - 0s - loss: 0.0093 - val_loss: 0.0191\n",
      "Epoch 90/250\n",
      "125/125 - 0s - loss: 0.0092 - val_loss: 0.0199\n",
      "Epoch 91/250\n",
      "125/125 - 0s - loss: 0.0092 - val_loss: 0.0188\n",
      "Epoch 92/250\n",
      "125/125 - 0s - loss: 0.0088 - val_loss: 0.0195\n",
      "Epoch 93/250\n",
      "125/125 - 0s - loss: 0.0085 - val_loss: 0.0186\n",
      "Epoch 94/250\n",
      "125/125 - 0s - loss: 0.0083 - val_loss: 0.0197\n",
      "Epoch 95/250\n",
      "125/125 - 0s - loss: 0.0083 - val_loss: 0.0186\n",
      "Epoch 96/250\n",
      "125/125 - 0s - loss: 0.0081 - val_loss: 0.0195\n",
      "Epoch 97/250\n",
      "125/125 - 0s - loss: 0.0080 - val_loss: 0.0185\n",
      "Epoch 98/250\n",
      "125/125 - 0s - loss: 0.0078 - val_loss: 0.0194\n",
      "Epoch 99/250\n",
      "125/125 - 0s - loss: 0.0076 - val_loss: 0.0187\n",
      "Epoch 100/250\n",
      "125/125 - 0s - loss: 0.0074 - val_loss: 0.0193\n",
      "Epoch 101/250\n",
      "125/125 - 0s - loss: 0.0073 - val_loss: 0.0190\n",
      "Epoch 102/250\n",
      "125/125 - 0s - loss: 0.0071 - val_loss: 0.0192\n",
      "Epoch 103/250\n",
      "125/125 - 0s - loss: 0.0071 - val_loss: 0.0194\n",
      "Epoch 104/250\n",
      "125/125 - 0s - loss: 0.0070 - val_loss: 0.0192\n",
      "Epoch 105/250\n",
      "125/125 - 0s - loss: 0.0070 - val_loss: 0.0195\n",
      "Epoch 106/250\n",
      "125/125 - 0s - loss: 0.0068 - val_loss: 0.0194\n",
      "Epoch 107/250\n",
      "125/125 - 0s - loss: 0.0065 - val_loss: 0.0192\n",
      "Epoch 108/250\n",
      "125/125 - 0s - loss: 0.0062 - val_loss: 0.0195\n",
      "Epoch 109/250\n",
      "125/125 - 0s - loss: 0.0061 - val_loss: 0.0192\n",
      "Epoch 110/250\n",
      "125/125 - 0s - loss: 0.0060 - val_loss: 0.0194\n",
      "Epoch 111/250\n",
      "125/125 - 0s - loss: 0.0059 - val_loss: 0.0196\n",
      "Epoch 112/250\n",
      "125/125 - 0s - loss: 0.0058 - val_loss: 0.0192\n",
      "Epoch 113/250\n",
      "125/125 - 0s - loss: 0.0057 - val_loss: 0.0199\n",
      "Epoch 114/250\n",
      "125/125 - 0s - loss: 0.0055 - val_loss: 0.0195\n",
      "Epoch 115/250\n",
      "125/125 - 0s - loss: 0.0054 - val_loss: 0.0198\n",
      "Epoch 116/250\n",
      "125/125 - 0s - loss: 0.0052 - val_loss: 0.0196\n",
      "Epoch 117/250\n",
      "125/125 - 0s - loss: 0.0051 - val_loss: 0.0199\n",
      "Epoch 118/250\n",
      "125/125 - 0s - loss: 0.0050 - val_loss: 0.0199\n",
      "Epoch 119/250\n",
      "125/125 - 0s - loss: 0.0049 - val_loss: 0.0199\n",
      "Epoch 120/250\n",
      "125/125 - 0s - loss: 0.0049 - val_loss: 0.0207\n",
      "Epoch 121/250\n",
      "125/125 - 0s - loss: 0.0048 - val_loss: 0.0200\n",
      "Epoch 122/250\n",
      "125/125 - 0s - loss: 0.0047 - val_loss: 0.0208\n",
      "Epoch 123/250\n",
      "125/125 - 0s - loss: 0.0045 - val_loss: 0.0200\n",
      "Epoch 124/250\n",
      "125/125 - 0s - loss: 0.0044 - val_loss: 0.0205\n",
      "Epoch 125/250\n",
      "125/125 - 0s - loss: 0.0043 - val_loss: 0.0200\n",
      "Epoch 126/250\n",
      "125/125 - 0s - loss: 0.0042 - val_loss: 0.0207\n",
      "Epoch 127/250\n",
      "125/125 - 0s - loss: 0.0041 - val_loss: 0.0203\n",
      "Epoch 128/250\n",
      "125/125 - 0s - loss: 0.0040 - val_loss: 0.0205\n",
      "Epoch 129/250\n",
      "125/125 - 0s - loss: 0.0039 - val_loss: 0.0206\n",
      "Epoch 130/250\n",
      "125/125 - 0s - loss: 0.0038 - val_loss: 0.0209\n",
      "Epoch 131/250\n",
      "125/125 - 0s - loss: 0.0037 - val_loss: 0.0207\n",
      "Epoch 132/250\n",
      "125/125 - 0s - loss: 0.0037 - val_loss: 0.0212\n",
      "Epoch 133/250\n",
      "125/125 - 0s - loss: 0.0036 - val_loss: 0.0208\n",
      "Epoch 134/250\n",
      "125/125 - 0s - loss: 0.0035 - val_loss: 0.0207\n",
      "Epoch 135/250\n",
      "125/125 - 0s - loss: 0.0034 - val_loss: 0.0211\n",
      "Epoch 136/250\n",
      "125/125 - 0s - loss: 0.0033 - val_loss: 0.0209\n",
      "Epoch 137/250\n",
      "125/125 - 0s - loss: 0.0032 - val_loss: 0.0214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 138/250\n",
      "125/125 - 0s - loss: 0.0031 - val_loss: 0.0211\n",
      "Epoch 139/250\n",
      "125/125 - 0s - loss: 0.0031 - val_loss: 0.0215\n",
      "Epoch 140/250\n",
      "125/125 - 0s - loss: 0.0030 - val_loss: 0.0213\n",
      "Epoch 141/250\n",
      "125/125 - 0s - loss: 0.0029 - val_loss: 0.0215\n",
      "Epoch 142/250\n",
      "125/125 - 0s - loss: 0.0029 - val_loss: 0.0217\n",
      "Epoch 143/250\n",
      "125/125 - 0s - loss: 0.0028 - val_loss: 0.0216\n",
      "Epoch 144/250\n",
      "125/125 - 0s - loss: 0.0028 - val_loss: 0.0215\n",
      "Epoch 145/250\n",
      "125/125 - 0s - loss: 0.0027 - val_loss: 0.0218\n",
      "Epoch 146/250\n",
      "125/125 - 0s - loss: 0.0027 - val_loss: 0.0214\n",
      "Epoch 147/250\n",
      "125/125 - 0s - loss: 0.0026 - val_loss: 0.0220\n",
      "Epoch 148/250\n",
      "125/125 - 0s - loss: 0.0025 - val_loss: 0.0216\n",
      "Epoch 149/250\n",
      "125/125 - 0s - loss: 0.0024 - val_loss: 0.0219\n",
      "Epoch 150/250\n",
      "125/125 - 0s - loss: 0.0024 - val_loss: 0.0222\n",
      "Epoch 151/250\n",
      "125/125 - 0s - loss: 0.0023 - val_loss: 0.0217\n",
      "Epoch 152/250\n",
      "125/125 - 0s - loss: 0.0022 - val_loss: 0.0226\n",
      "Epoch 153/250\n",
      "125/125 - 0s - loss: 0.0022 - val_loss: 0.0217\n",
      "Epoch 154/250\n",
      "125/125 - 0s - loss: 0.0021 - val_loss: 0.0226\n",
      "Epoch 155/250\n",
      "125/125 - 0s - loss: 0.0021 - val_loss: 0.0218\n",
      "Epoch 156/250\n",
      "125/125 - 0s - loss: 0.0021 - val_loss: 0.0228\n",
      "Epoch 157/250\n",
      "125/125 - 0s - loss: 0.0020 - val_loss: 0.0220\n",
      "Epoch 158/250\n",
      "125/125 - 0s - loss: 0.0020 - val_loss: 0.0227\n",
      "Epoch 159/250\n",
      "125/125 - 0s - loss: 0.0019 - val_loss: 0.0223\n",
      "Epoch 160/250\n",
      "125/125 - 0s - loss: 0.0019 - val_loss: 0.0228\n",
      "Epoch 161/250\n",
      "125/125 - 0s - loss: 0.0018 - val_loss: 0.0226\n",
      "Epoch 162/250\n",
      "125/125 - 0s - loss: 0.0018 - val_loss: 0.0227\n",
      "Epoch 163/250\n",
      "125/125 - 0s - loss: 0.0018 - val_loss: 0.0229\n",
      "Epoch 164/250\n",
      "125/125 - 0s - loss: 0.0017 - val_loss: 0.0231\n",
      "Epoch 165/250\n",
      "125/125 - 0s - loss: 0.0017 - val_loss: 0.0229\n",
      "Epoch 166/250\n",
      "125/125 - 0s - loss: 0.0016 - val_loss: 0.0232\n",
      "Epoch 167/250\n",
      "125/125 - 0s - loss: 0.0016 - val_loss: 0.0230\n",
      "Epoch 168/250\n",
      "125/125 - 0s - loss: 0.0015 - val_loss: 0.0234\n",
      "Epoch 169/250\n",
      "125/125 - 0s - loss: 0.0015 - val_loss: 0.0232\n",
      "Epoch 170/250\n",
      "125/125 - 0s - loss: 0.0015 - val_loss: 0.0233\n",
      "Epoch 171/250\n",
      "125/125 - 0s - loss: 0.0014 - val_loss: 0.0231\n",
      "Epoch 172/250\n",
      "125/125 - 0s - loss: 0.0014 - val_loss: 0.0234\n",
      "Epoch 173/250\n",
      "125/125 - 0s - loss: 0.0013 - val_loss: 0.0233\n",
      "Epoch 174/250\n",
      "125/125 - 0s - loss: 0.0013 - val_loss: 0.0231\n",
      "Epoch 175/250\n",
      "125/125 - 0s - loss: 0.0013 - val_loss: 0.0236\n",
      "Epoch 176/250\n",
      "125/125 - 0s - loss: 0.0012 - val_loss: 0.0230\n",
      "Epoch 177/250\n",
      "125/125 - 0s - loss: 0.0012 - val_loss: 0.0235\n",
      "Epoch 178/250\n",
      "125/125 - 0s - loss: 0.0012 - val_loss: 0.0233\n",
      "Epoch 179/250\n",
      "125/125 - 0s - loss: 0.0012 - val_loss: 0.0237\n",
      "Epoch 180/250\n",
      "125/125 - 0s - loss: 0.0012 - val_loss: 0.0235\n",
      "Epoch 181/250\n",
      "125/125 - 0s - loss: 0.0011 - val_loss: 0.0239\n",
      "Epoch 182/250\n",
      "125/125 - 0s - loss: 0.0011 - val_loss: 0.0232\n",
      "Epoch 183/250\n",
      "125/125 - 0s - loss: 0.0011 - val_loss: 0.0243\n",
      "Epoch 184/250\n",
      "125/125 - 0s - loss: 0.0011 - val_loss: 0.0233\n",
      "Epoch 185/250\n",
      "125/125 - 0s - loss: 0.0010 - val_loss: 0.0242\n",
      "Epoch 186/250\n",
      "125/125 - 0s - loss: 9.9246e-04 - val_loss: 0.0238\n",
      "Epoch 187/250\n",
      "125/125 - 0s - loss: 9.7636e-04 - val_loss: 0.0241\n",
      "Epoch 188/250\n",
      "125/125 - 0s - loss: 9.3765e-04 - val_loss: 0.0240\n",
      "Epoch 189/250\n",
      "125/125 - 0s - loss: 9.2787e-04 - val_loss: 0.0239\n",
      "Epoch 190/250\n",
      "125/125 - 0s - loss: 9.2247e-04 - val_loss: 0.0243\n",
      "Epoch 191/250\n",
      "125/125 - 0s - loss: 9.0739e-04 - val_loss: 0.0240\n",
      "Epoch 192/250\n",
      "125/125 - 0s - loss: 8.8573e-04 - val_loss: 0.0244\n",
      "Epoch 193/250\n",
      "125/125 - 0s - loss: 8.5868e-04 - val_loss: 0.0241\n",
      "Epoch 194/250\n",
      "125/125 - 0s - loss: 8.3746e-04 - val_loss: 0.0247\n",
      "Epoch 195/250\n",
      "125/125 - 0s - loss: 8.2037e-04 - val_loss: 0.0241\n",
      "Epoch 196/250\n",
      "125/125 - 0s - loss: 8.0390e-04 - val_loss: 0.0248\n",
      "Epoch 197/250\n",
      "125/125 - 0s - loss: 7.7886e-04 - val_loss: 0.0243\n",
      "Epoch 198/250\n",
      "125/125 - 0s - loss: 7.7148e-04 - val_loss: 0.0245\n",
      "Epoch 199/250\n",
      "125/125 - 0s - loss: 7.5623e-04 - val_loss: 0.0244\n",
      "Epoch 200/250\n",
      "125/125 - 0s - loss: 7.4826e-04 - val_loss: 0.0249\n",
      "Epoch 201/250\n",
      "125/125 - 0s - loss: 7.2846e-04 - val_loss: 0.0244\n",
      "Epoch 202/250\n",
      "125/125 - 0s - loss: 7.1412e-04 - val_loss: 0.0249\n",
      "Epoch 203/250\n",
      "125/125 - 0s - loss: 7.0127e-04 - val_loss: 0.0245\n",
      "Epoch 204/250\n",
      "125/125 - 0s - loss: 6.7331e-04 - val_loss: 0.0246\n",
      "Epoch 205/250\n",
      "125/125 - 0s - loss: 6.4269e-04 - val_loss: 0.0243\n",
      "Epoch 206/250\n",
      "125/125 - 0s - loss: 6.4611e-04 - val_loss: 0.0250\n",
      "Epoch 207/250\n",
      "125/125 - 0s - loss: 6.2317e-04 - val_loss: 0.0247\n",
      "Epoch 208/250\n",
      "125/125 - 0s - loss: 6.0395e-04 - val_loss: 0.0249\n",
      "Epoch 209/250\n",
      "125/125 - 0s - loss: 5.9375e-04 - val_loss: 0.0248\n",
      "Epoch 210/250\n",
      "125/125 - 0s - loss: 5.7463e-04 - val_loss: 0.0246\n",
      "Epoch 211/250\n",
      "125/125 - 0s - loss: 5.7959e-04 - val_loss: 0.0249\n",
      "Epoch 212/250\n",
      "125/125 - 0s - loss: 5.7863e-04 - val_loss: 0.0247\n",
      "Epoch 213/250\n",
      "125/125 - 0s - loss: 5.7263e-04 - val_loss: 0.0252\n",
      "Epoch 214/250\n",
      "125/125 - 0s - loss: 5.5751e-04 - val_loss: 0.0249\n",
      "Epoch 215/250\n",
      "125/125 - 0s - loss: 5.3529e-04 - val_loss: 0.0250\n",
      "Epoch 216/250\n",
      "125/125 - 0s - loss: 5.3399e-04 - val_loss: 0.0250\n",
      "Epoch 217/250\n",
      "125/125 - 0s - loss: 5.2473e-04 - val_loss: 0.0252\n",
      "Epoch 218/250\n",
      "125/125 - 0s - loss: 5.0707e-04 - val_loss: 0.0252\n",
      "Epoch 219/250\n",
      "125/125 - 0s - loss: 4.9479e-04 - val_loss: 0.0253\n",
      "Epoch 220/250\n",
      "125/125 - 0s - loss: 4.9247e-04 - val_loss: 0.0252\n",
      "Epoch 221/250\n",
      "125/125 - 0s - loss: 4.9660e-04 - val_loss: 0.0251\n",
      "Epoch 222/250\n",
      "125/125 - 0s - loss: 4.8603e-04 - val_loss: 0.0249\n",
      "Epoch 223/250\n",
      "125/125 - 0s - loss: 4.7443e-04 - val_loss: 0.0252\n",
      "Epoch 224/250\n",
      "125/125 - 0s - loss: 4.7399e-04 - val_loss: 0.0253\n",
      "Epoch 225/250\n",
      "125/125 - 0s - loss: 4.6226e-04 - val_loss: 0.0251\n",
      "Epoch 226/250\n",
      "125/125 - 0s - loss: 4.5128e-04 - val_loss: 0.0252\n",
      "Epoch 227/250\n",
      "125/125 - 0s - loss: 4.6613e-04 - val_loss: 0.0250\n",
      "Epoch 228/250\n",
      "125/125 - 0s - loss: 4.5024e-04 - val_loss: 0.0254\n",
      "Epoch 229/250\n",
      "125/125 - 0s - loss: 4.3793e-04 - val_loss: 0.0251\n",
      "Epoch 230/250\n",
      "125/125 - 0s - loss: 4.5199e-04 - val_loss: 0.0257\n",
      "Epoch 231/250\n",
      "125/125 - 0s - loss: 7.6324e-04 - val_loss: 0.0272\n",
      "Epoch 232/250\n",
      "125/125 - 0s - loss: 0.0015 - val_loss: 0.0282\n",
      "Epoch 233/250\n",
      "125/125 - 0s - loss: 0.0012 - val_loss: 0.0295\n",
      "Epoch 234/250\n",
      "125/125 - 0s - loss: 8.8786e-04 - val_loss: 0.0258\n",
      "Epoch 235/250\n",
      "125/125 - 0s - loss: 0.0012 - val_loss: 0.0238\n",
      "Epoch 236/250\n",
      "125/125 - 0s - loss: 0.0010 - val_loss: 0.0239\n",
      "Epoch 237/250\n",
      "125/125 - 0s - loss: 6.1531e-04 - val_loss: 0.0237\n",
      "Epoch 238/250\n",
      "125/125 - 0s - loss: 4.8093e-04 - val_loss: 0.0239\n",
      "Epoch 239/250\n",
      "125/125 - 0s - loss: 4.6710e-04 - val_loss: 0.0236\n",
      "Epoch 240/250\n",
      "125/125 - 0s - loss: 4.2398e-04 - val_loss: 0.0240\n",
      "Epoch 241/250\n",
      "125/125 - 0s - loss: 3.8620e-04 - val_loss: 0.0243\n",
      "Epoch 242/250\n",
      "125/125 - 0s - loss: 3.7823e-04 - val_loss: 0.0245\n",
      "Epoch 243/250\n",
      "125/125 - 0s - loss: 3.6541e-04 - val_loss: 0.0248\n",
      "Epoch 244/250\n",
      "125/125 - 0s - loss: 3.5706e-04 - val_loss: 0.0247\n",
      "Epoch 245/250\n",
      "125/125 - 0s - loss: 3.4638e-04 - val_loss: 0.0250\n",
      "Epoch 246/250\n",
      "125/125 - 0s - loss: 3.4794e-04 - val_loss: 0.0248\n",
      "Epoch 247/250\n",
      "125/125 - 0s - loss: 3.4013e-04 - val_loss: 0.0251\n",
      "Epoch 248/250\n",
      "125/125 - 0s - loss: 3.3855e-04 - val_loss: 0.0251\n",
      "Epoch 249/250\n",
      "125/125 - 0s - loss: 3.3252e-04 - val_loss: 0.0251\n",
      "Epoch 250/250\n",
      "125/125 - 0s - loss: 3.3023e-04 - val_loss: 0.0252\n",
      "Train Loss: 0.0003302305412944406\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    y_train,\n",
    "    y_train,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(y_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "loss = history.history[\"loss\"][-1]\n",
    "print(f\"Train Loss: {loss}\")\n",
    "\n",
    "write_dir = 'History/'\n",
    "model.save('History/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e82ea914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means: [-0.04197179  0.06426372 -0.1942337  -0.01409939 -0.0045891  -0.03661692]\n",
      "Evals: [3.03599259 2.57547879 2.35967081 2.1449569  1.99991735 1.93928994] \n"
     ]
    }
   ],
   "source": [
    "y_song = model.predict((y_test_song).reshape(1,16,96,96), batch_size=BATCH_SIZE)\n",
    "\n",
    "midi.samples_to_midi(y_song[0], write_dir + 'test.mid', 16)\n",
    "make_rand_songs_normalized(write_dir, rand_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a01b24ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 45352), started 0:57:32 ago. (Use '!kill 45352' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-629f6fbed82c07cd\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-629f6fbed82c07cd\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (IC)",
   "language": "python",
   "name": "ic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
