{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "53292e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import (Activation, BatchNormalization, Dense,\n",
    "                                     Dropout, Flatten, Input, Reshape,\n",
    "                                     TimeDistributed)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "260e61e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d72d9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31ccf1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 100\n",
    "LR = 0.001\n",
    "WRITE_HISTORY = True\n",
    "NUM_RAND_SONGS = 10\n",
    "DO_RATE = 0.1\n",
    "BN_M = 0.9\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "MAX_LENGTH = 16\n",
    "PARAM_SIZE = 120\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d014c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_samples = np.load('samples.npy')\n",
    "y_lengths = np.load('lengths.npy')\n",
    "# y_samples = np.load('samplesBach.npy')\n",
    "# y_lengths = np.load('lengthsBach.npy')\n",
    "num_songs = y_lengths.shape[0]\n",
    "\n",
    "y_shape = (num_songs, MAX_LENGTH) + y_samples.shape[1:]\n",
    "y_orig = np.zeros(y_shape, dtype=y_samples.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85096883",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_ix = 0\n",
    "for i in range(num_songs):\n",
    "    end_ix = cur_ix + y_lengths[i]\n",
    "    for j in range(MAX_LENGTH):\n",
    "        k = j % (end_ix - cur_ix) \n",
    "        y_orig[i,j] = y_samples[cur_ix + k]\n",
    "    cur_ix = end_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d939754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.copy(y_orig)\n",
    "\n",
    "y_train = y[:175]\n",
    "y_valid = y[175:]\n",
    "\n",
    "y_test_song = np.copy(y[0])\n",
    "midi.samples_to_midi(y_test_song, 'gt.mid', 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9091b0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_in = Input(shape=y_shape[1:])\n",
    "x = Reshape((y_shape[1], -1))(x_in)\n",
    "x = TimeDistributed(Dense(2000, activation='relu'))(x)\n",
    "x = TimeDistributed(Dense(200, activation='relu'))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(1600, activation='relu')(x)\n",
    "x = Dense(PARAM_SIZE)(x)\n",
    "x = BatchNormalization(momentum=BN_M, name='pre_encoder')(x)\n",
    "\n",
    "x = Dense(1600, name='encoder')(x)\n",
    "x = BatchNormalization(momentum=BN_M)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(DO_RATE)(x)\n",
    "x = Dense(MAX_LENGTH * 200)(x)\n",
    "x = Reshape((MAX_LENGTH, 200))(x)\n",
    "x = TimeDistributed(BatchNormalization(momentum=BN_M))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(DO_RATE)(x)\n",
    "x = TimeDistributed(Dense(2000))(x)\n",
    "x = TimeDistributed(BatchNormalization(momentum=BN_M))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(DO_RATE)(x)\n",
    "x = TimeDistributed(Dense(y_shape[2] * y_shape[3], activation='sigmoid'))(x)\n",
    "x = Reshape((y_shape[1], y_shape[2], y_shape[3]))(x)\n",
    "\n",
    "model = Model(x_in, x)\n",
    "model.compile(optimizer=RMSprop(learning_rate=LR), loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c9bae11",
   "metadata": {},
   "outputs": [],
   "source": [
    "func = K.function([model.get_layer('encoder').input, K.learning_phase()], [model.layers[-1].output])\n",
    "enc = Model(inputs=model.input, outputs=model.get_layer('pre_encoder').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "617f7bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_vecs = np.random.normal(0.0, 1.0, (NUM_RAND_SONGS, PARAM_SIZE))\n",
    "np.save('rand.npy', rand_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0d54af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(\n",
    "    \"logs\",\n",
    "    datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
    ")\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=log_dir),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2eb91f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 175 samples, validate on 63 samples\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eller\\anaconda3\\envs\\IC\\lib\\site-packages\\keras\\engine\\training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175/175 - 9s - loss: 0.5661 - val_loss: 0.6461\n",
      "Epoch 2/100\n",
      "175/175 - 4s - loss: 0.0753 - val_loss: 0.4836\n",
      "Epoch 3/100\n",
      "175/175 - 4s - loss: 0.0456 - val_loss: 0.4178\n",
      "Epoch 4/100\n",
      "175/175 - 4s - loss: 0.0313 - val_loss: 0.3320\n",
      "Epoch 5/100\n",
      "175/175 - 4s - loss: 0.0262 - val_loss: 0.2488\n",
      "Epoch 6/100\n",
      "175/175 - 4s - loss: 0.0239 - val_loss: 0.1741\n",
      "Epoch 7/100\n",
      "175/175 - 4s - loss: 0.0223 - val_loss: 0.1387\n",
      "Epoch 8/100\n",
      "175/175 - 4s - loss: 0.0212 - val_loss: 0.0978\n",
      "Epoch 9/100\n",
      "175/175 - 4s - loss: 0.0204 - val_loss: 0.0681\n",
      "Epoch 10/100\n",
      "175/175 - 4s - loss: 0.0197 - val_loss: 0.0652\n",
      "Epoch 11/100\n",
      "175/175 - 4s - loss: 0.0192 - val_loss: 0.0496\n",
      "Epoch 12/100\n",
      "175/175 - 4s - loss: 0.0188 - val_loss: 0.0327\n",
      "Epoch 13/100\n",
      "175/175 - 4s - loss: 0.0185 - val_loss: 0.0359\n",
      "Epoch 14/100\n",
      "175/175 - 4s - loss: 0.0183 - val_loss: 0.0284\n",
      "Epoch 15/100\n",
      "175/175 - 4s - loss: 0.0179 - val_loss: 0.0236\n",
      "Epoch 16/100\n",
      "175/175 - 4s - loss: 0.0178 - val_loss: 0.0223\n",
      "Epoch 17/100\n",
      "175/175 - 4s - loss: 0.0176 - val_loss: 0.0225\n",
      "Epoch 18/100\n",
      "175/175 - 4s - loss: 0.0173 - val_loss: 0.0199\n",
      "Epoch 19/100\n",
      "175/175 - 4s - loss: 0.0172 - val_loss: 0.0201\n",
      "Epoch 20/100\n",
      "175/175 - 4s - loss: 0.0169 - val_loss: 0.0198\n",
      "Epoch 21/100\n",
      "175/175 - 4s - loss: 0.0168 - val_loss: 0.0208\n",
      "Epoch 22/100\n",
      "175/175 - 3s - loss: 0.0168 - val_loss: 0.0201\n",
      "Epoch 23/100\n",
      "175/175 - 4s - loss: 0.0166 - val_loss: 0.0190\n",
      "Epoch 24/100\n",
      "175/175 - 3s - loss: 0.0164 - val_loss: 0.0187\n",
      "Epoch 25/100\n",
      "175/175 - 4s - loss: 0.0164 - val_loss: 0.0187\n",
      "Epoch 26/100\n",
      "175/175 - 3s - loss: 0.0161 - val_loss: 0.0189\n",
      "Epoch 27/100\n",
      "175/175 - 4s - loss: 0.0160 - val_loss: 0.0187\n",
      "Epoch 28/100\n",
      "175/175 - 3s - loss: 0.0159 - val_loss: 0.0184\n",
      "Epoch 29/100\n",
      "175/175 - 3s - loss: 0.0157 - val_loss: 0.0186\n",
      "Epoch 30/100\n",
      "175/175 - 4s - loss: 0.0155 - val_loss: 0.0185\n",
      "Epoch 31/100\n",
      "175/175 - 3s - loss: 0.0154 - val_loss: 0.0197\n",
      "Epoch 32/100\n",
      "175/175 - 4s - loss: 0.0156 - val_loss: 0.0193\n",
      "Epoch 33/100\n",
      "175/175 - 3s - loss: 0.0154 - val_loss: 0.0185\n",
      "Epoch 34/100\n",
      "175/175 - 3s - loss: 0.0153 - val_loss: 0.0182\n",
      "Epoch 35/100\n",
      "175/175 - 3s - loss: 0.0146 - val_loss: 0.0182\n",
      "Epoch 36/100\n",
      "175/175 - 4s - loss: 0.0143 - val_loss: 0.0185\n",
      "Epoch 37/100\n",
      "175/175 - 3s - loss: 0.0143 - val_loss: 0.0176\n",
      "Epoch 38/100\n",
      "175/175 - 3s - loss: 0.0139 - val_loss: 0.0176\n",
      "Epoch 39/100\n",
      "175/175 - 4s - loss: 0.0138 - val_loss: 0.0188\n",
      "Epoch 40/100\n",
      "175/175 - 3s - loss: 0.0141 - val_loss: 0.0183\n",
      "Epoch 41/100\n",
      "175/175 - 3s - loss: 0.0137 - val_loss: 0.0186\n",
      "Epoch 42/100\n",
      "175/175 - 4s - loss: 0.0139 - val_loss: 0.0181\n",
      "Epoch 43/100\n",
      "175/175 - 4s - loss: 0.0133 - val_loss: 0.0175\n",
      "Epoch 44/100\n",
      "175/175 - 3s - loss: 0.0129 - val_loss: 0.0176\n",
      "Epoch 45/100\n",
      "175/175 - 3s - loss: 0.0126 - val_loss: 0.0173\n",
      "Epoch 46/100\n",
      "175/175 - 3s - loss: 0.0124 - val_loss: 0.0177\n",
      "Epoch 47/100\n",
      "175/175 - 3s - loss: 0.0124 - val_loss: 0.0185\n",
      "Epoch 48/100\n",
      "175/175 - 3s - loss: 0.0125 - val_loss: 0.0177\n",
      "Epoch 49/100\n",
      "175/175 - 3s - loss: 0.0124 - val_loss: 0.0182\n",
      "Epoch 50/100\n",
      "175/175 - 4s - loss: 0.0123 - val_loss: 0.0176\n",
      "Epoch 51/100\n",
      "175/175 - 4s - loss: 0.0118 - val_loss: 0.0173\n",
      "Epoch 52/100\n",
      "175/175 - 3s - loss: 0.0113 - val_loss: 0.0172\n",
      "Epoch 53/100\n",
      "175/175 - 4s - loss: 0.0112 - val_loss: 0.0174\n",
      "Epoch 54/100\n",
      "175/175 - 3s - loss: 0.0112 - val_loss: 0.0169\n",
      "Epoch 55/100\n",
      "175/175 - 4s - loss: 0.0111 - val_loss: 0.0173\n",
      "Epoch 56/100\n",
      "175/175 - 4s - loss: 0.0112 - val_loss: 0.0174\n",
      "Epoch 57/100\n",
      "175/175 - 3s - loss: 0.0110 - val_loss: 0.0182\n",
      "Epoch 58/100\n",
      "175/175 - 4s - loss: 0.0108 - val_loss: 0.0182\n",
      "Epoch 59/100\n",
      "175/175 - 4s - loss: 0.0104 - val_loss: 0.0173\n",
      "Epoch 60/100\n",
      "175/175 - 4s - loss: 0.0100 - val_loss: 0.0174\n",
      "Epoch 61/100\n",
      "175/175 - 4s - loss: 0.0098 - val_loss: 0.0173\n",
      "Epoch 62/100\n",
      "175/175 - 4s - loss: 0.0097 - val_loss: 0.0175\n",
      "Epoch 63/100\n",
      "175/175 - 4s - loss: 0.0096 - val_loss: 0.0171\n",
      "Epoch 64/100\n",
      "175/175 - 4s - loss: 0.0093 - val_loss: 0.0174\n",
      "Epoch 65/100\n",
      "175/175 - 4s - loss: 0.0094 - val_loss: 0.0173\n",
      "Epoch 66/100\n",
      "175/175 - 3s - loss: 0.0094 - val_loss: 0.0171\n",
      "Epoch 67/100\n",
      "175/175 - 4s - loss: 0.0092 - val_loss: 0.0181\n",
      "Epoch 68/100\n",
      "175/175 - 4s - loss: 0.0090 - val_loss: 0.0178\n",
      "Epoch 69/100\n",
      "175/175 - 4s - loss: 0.0087 - val_loss: 0.0176\n",
      "Epoch 70/100\n",
      "175/175 - 3s - loss: 0.0084 - val_loss: 0.0177\n",
      "Epoch 71/100\n",
      "175/175 - 3s - loss: 0.0085 - val_loss: 0.0187\n",
      "Epoch 72/100\n",
      "175/175 - 4s - loss: 0.0087 - val_loss: 0.0177\n",
      "Epoch 73/100\n",
      "175/175 - 4s - loss: 0.0082 - val_loss: 0.0179\n",
      "Epoch 74/100\n",
      "175/175 - 4s - loss: 0.0081 - val_loss: 0.0181\n",
      "Epoch 75/100\n",
      "175/175 - 4s - loss: 0.0080 - val_loss: 0.0179\n",
      "Epoch 76/100\n",
      "175/175 - 4s - loss: 0.0079 - val_loss: 0.0188\n",
      "Epoch 77/100\n",
      "175/175 - 3s - loss: 0.0077 - val_loss: 0.0177\n",
      "Epoch 78/100\n",
      "175/175 - 4s - loss: 0.0074 - val_loss: 0.0175\n",
      "Epoch 79/100\n",
      "175/175 - 4s - loss: 0.0071 - val_loss: 0.0175\n",
      "Epoch 80/100\n",
      "175/175 - 3s - loss: 0.0071 - val_loss: 0.0174\n",
      "Epoch 81/100\n",
      "175/175 - 4s - loss: 0.0070 - val_loss: 0.0173\n",
      "Epoch 82/100\n",
      "175/175 - 4s - loss: 0.0071 - val_loss: 0.0182\n",
      "Epoch 83/100\n",
      "175/175 - 3s - loss: 0.0071 - val_loss: 0.0180\n",
      "Epoch 84/100\n",
      "175/175 - 4s - loss: 0.0069 - val_loss: 0.0181\n",
      "Epoch 85/100\n",
      "175/175 - 3s - loss: 0.0067 - val_loss: 0.0180\n",
      "Epoch 86/100\n",
      "175/175 - 4s - loss: 0.0066 - val_loss: 0.0181\n",
      "Epoch 87/100\n",
      "175/175 - 4s - loss: 0.0066 - val_loss: 0.0181\n",
      "Epoch 88/100\n",
      "175/175 - 3s - loss: 0.0065 - val_loss: 0.0178\n",
      "Epoch 89/100\n",
      "175/175 - 4s - loss: 0.0062 - val_loss: 0.0179\n",
      "Epoch 90/100\n",
      "175/175 - 4s - loss: 0.0060 - val_loss: 0.0176\n",
      "Epoch 91/100\n",
      "175/175 - 4s - loss: 0.0058 - val_loss: 0.0182\n",
      "Epoch 92/100\n",
      "175/175 - 4s - loss: 0.0059 - val_loss: 0.0179\n",
      "Epoch 93/100\n",
      "175/175 - 4s - loss: 0.0058 - val_loss: 0.0183\n",
      "Epoch 94/100\n",
      "175/175 - 4s - loss: 0.0057 - val_loss: 0.0185\n",
      "Epoch 95/100\n",
      "175/175 - 4s - loss: 0.0056 - val_loss: 0.0183\n",
      "Epoch 96/100\n",
      "175/175 - 4s - loss: 0.0055 - val_loss: 0.0183\n",
      "Epoch 97/100\n",
      "175/175 - 4s - loss: 0.0053 - val_loss: 0.0181\n",
      "Epoch 98/100\n",
      "175/175 - 3s - loss: 0.0054 - val_loss: 0.0179\n",
      "Epoch 99/100\n",
      "175/175 - 3s - loss: 0.0053 - val_loss: 0.0181\n",
      "Epoch 100/100\n",
      "175/175 - 3s - loss: 0.0054 - val_loss: 0.0182\n",
      "Train Loss: 0.005364460048398801\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    y_train,\n",
    "    y_train,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(y_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "loss = history.history[\"loss\"][-1]\n",
    "print(f\"Train Loss: {loss}\")\n",
    "\n",
    "write_dir = 'HistoryAuto/'\n",
    "model.save('HistoryAuto/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "82b855a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rand_songs(write_dir, rand_vecs):\n",
    "    for i in range(rand_vecs.shape[0]):\n",
    "        x_rand = rand_vecs[i:i+1]\n",
    "        y_song = func([x_rand, 0])[0]\n",
    "        midi.samples_to_midi(y_song[0], write_dir + 'randGame' + str(i) + '.mid', 16, 0.5)\n",
    "\n",
    "def make_rand_songs_normalized(write_dir, rand_vecs):\n",
    "    x_enc = np.squeeze(enc.predict(y_orig))\n",
    "\n",
    "    x_mean = np.mean(x_enc, axis=0)\n",
    "    x_cov = np.cov((x_enc - x_mean).T)\n",
    "    _, s, v = np.linalg.svd(x_cov)\n",
    "    e = np.sqrt(s)\n",
    "\n",
    "    print(f\"Means: {x_mean[:6]}\")\n",
    "    print(f\"Evals: {e[:6]} \")\n",
    "\n",
    "    x_vecs = x_mean + np.dot(rand_vecs * e, v)\n",
    "    make_rand_songs(write_dir, x_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e82ea914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means: [0.02104055 0.17722142 0.09916551 0.16378419 0.02010539 0.062884  ]\n",
      "Evals: [4.58530266 3.55321573 3.27695911 3.12697031 2.93756239 2.77289109] \n"
     ]
    }
   ],
   "source": [
    "y_song = model.predict((y_test_song).reshape(1,16,96,96), batch_size=BATCH_SIZE)\n",
    "\n",
    "midi.samples_to_midi(y_song[0], write_dir + 'test.mid', 16)\n",
    "make_rand_songs_normalized(write_dir, rand_vecs)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9120da6c2d63ded445b1a09e31569bbaba4e2e721b03136355509f1402b65420"
  },
  "kernelspec": {
   "display_name": "Python (IC)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
