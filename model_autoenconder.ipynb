{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "53292e1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import (Activation, BatchNormalization, Dense,\n",
    "                                     Dropout, Flatten, Input, Reshape,\n",
    "                                     TimeDistributed)\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6780a81d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "260e61e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d72d9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import midi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31ccf1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCHS = 400\n",
    "LR = 0.001\n",
    "WRITE_HISTORY = True\n",
    "NUM_RAND_SONGS = 10\n",
    "DO_RATE = 0.1\n",
    "BN_M = 0.9\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "MAX_LENGTH = 16\n",
    "PARAM_SIZE = 120\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d014c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_samples = np.load('samples.npy')\n",
    "y_lengths = np.load('lengths.npy')\n",
    "num_songs = y_lengths.shape[0]\n",
    "\n",
    "y_shape = (num_songs, MAX_LENGTH) + y_samples.shape[1:]\n",
    "y_orig = np.zeros(y_shape, dtype=y_samples.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc293842",
   "metadata": {},
   "source": [
    "* y_samples = (_, 96, 96)\n",
    "* y_lengths = (238,)\n",
    "* y_shape = (238, 16, 96, 96)\n",
    "* y_origin = Array de zeros (238, 16, 96, 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85096883",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_ix = 0\n",
    "for i in range(num_songs):\n",
    "    end_ix = cur_ix + y_lengths[i]\n",
    "    for j in range(MAX_LENGTH):\n",
    "        k = j % (end_ix - cur_ix) \n",
    "        y_orig[i,j] = y_samples[cur_ix + k]\n",
    "    cur_ix = end_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d939754d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.copy(y_orig)\n",
    "\n",
    "y_train = y[:125]\n",
    "y_valid = y[125:]\n",
    "\n",
    "y_test_song = np.copy(y[0])\n",
    "midi.samples_to_midi(y_test_song, 'gt.mid', 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9091b0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\eller\\anaconda3\\envs\\IC\\lib\\site-packages\\keras\\layers\\normalization\\batch_normalization.py:520: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "x_in = Input(shape=y_shape[1:])\n",
    "x = Reshape((y_shape[1], -1))(x_in)\n",
    "x = TimeDistributed(Dense(2000, activation='relu'))(x)\n",
    "x = TimeDistributed(Dense(200, activation='relu'))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(1600, activation='relu')(x)\n",
    "x = Dense(PARAM_SIZE)(x)\n",
    "x = BatchNormalization(momentum=BN_M, name='pre_encoder')(x)\n",
    "\n",
    "x = Dense(1600, name='encoder')(x)\n",
    "x = BatchNormalization(momentum=BN_M)(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(DO_RATE)(x)\n",
    "x = Dense(MAX_LENGTH * 200)(x)\n",
    "x = Reshape((MAX_LENGTH, 200))(x)\n",
    "x = TimeDistributed(BatchNormalization(momentum=BN_M))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(DO_RATE)(x)\n",
    "x = TimeDistributed(Dense(2000))(x)\n",
    "x = TimeDistributed(BatchNormalization(momentum=BN_M))(x)\n",
    "x = Activation('relu')(x)\n",
    "x = Dropout(DO_RATE)(x)\n",
    "x = TimeDistributed(Dense(y_shape[2] * y_shape[3], activation='sigmoid'))(x)\n",
    "x = Reshape((y_shape[1], y_shape[2], y_shape[3]))(x)\n",
    "\n",
    "model = Model(x_in, x)\n",
    "model.compile(optimizer=RMSprop(learning_rate=LR), loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8c0d834b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 16, 96, 96)]      0         \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 16, 9216)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed (TimeDistri (None, 16, 2000)          18434000  \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 16, 200)           400200    \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3200)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1600)              5121600   \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 120)               192120    \n",
      "_________________________________________________________________\n",
      "pre_encoder (BatchNormalizat (None, 120)               480       \n",
      "_________________________________________________________________\n",
      "encoder (Dense)              (None, 1600)              193600    \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1600)              6400      \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 3200)              5123200   \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 16, 200)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_2 (TimeDist (None, 16, 200)           800       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16, 200)           0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 200)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 16, 2000)          402000    \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 16, 2000)          8000      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 16, 2000)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 2000)          0         \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 16, 9216)          18441216  \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 16, 96, 96)        0         \n",
      "=================================================================\n",
      "Total params: 48,323,616\n",
      "Trainable params: 48,315,776\n",
      "Non-trainable params: 7,840\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c9bae11",
   "metadata": {},
   "outputs": [],
   "source": [
    "func = K.function([model.get_layer('encoder').input, K.learning_phase()], [model.layers[-1].output])\n",
    "enc = Model(inputs=model.input, outputs=model.get_layer('pre_encoder').output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a05a4b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'pre_encoder/batchnorm/add_1:0' shape=(None, 120) dtype=float32>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_layer('pre_encoder').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "617f7bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rand_vecs = np.random.normal(0.0, 1.0, (NUM_RAND_SONGS, PARAM_SIZE))\n",
    "np.save('rand.npy', rand_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0d54af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = os.path.join(\n",
    "    \"logs\",\n",
    "    datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"),\n",
    ")\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=log_dir),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcdbae28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_model():\n",
    "#     def rounded_accuracy(y_true, y_pred):\n",
    "#         return tf.keras.metrics.binary_accuracy(\n",
    "#             tf.round(y_true),\n",
    "#             tf.round(y_pred),\n",
    "#         )\n",
    "    \n",
    "#     stacked_encoder = tf.keras.models.Sequential([\n",
    "#         Input(shape=(16,96,96)),\n",
    "#         Reshape((16, -1)),\n",
    "#         TimeDistributed(Dense(2000, activation='relu')),\n",
    "#         TimeDistributed(Dense(200, activation='relu')),\n",
    "#         Flatten(),\n",
    "#         Dense(1600, activation='relu'),\n",
    "#         Dense(PARAM_SIZE),\n",
    "#         BatchNormalization(momentum=BN_M, name='pre_encoder')\n",
    "#     ])\n",
    "#     stacked_decoder = tf.keras.models.Sequential([\n",
    "#         Dense(1600, name='encoder'),\n",
    "#         BatchNormalization(momentum=BN_M),\n",
    "#         Activation('relu'),\n",
    "#         Dense(MAX_LENGTH * 200),\n",
    "#         Reshape((MAX_LENGTH, 200)),\n",
    "#         TimeDistributed(BatchNormalization(momentum=BN_M)),\n",
    "#         Activation('relu'),\n",
    "#         TimeDistributed(Dense(2000)),\n",
    "#         TimeDistributed(BatchNormalization(momentum=BN_M)),\n",
    "#         Activation('relu'),\n",
    "#         TimeDistributed(Dense(96 * 96, activation='sigmoid')),\n",
    "#         Reshape((16,96,96))\n",
    "#     ])\n",
    "#     stacked_ae = tf.keras.models.Sequential([stacked_encoder, stacked_decoder])\n",
    "\n",
    "#     stacked_ae.compile(\n",
    "#         loss=\"binary_crossentropy\",\n",
    "#         optimizer= RMSprop(learning_rate=LR),\n",
    "#         metrics=[rounded_accuracy],\n",
    "#     )\n",
    "\n",
    "#     return stacked_encoder, stacked_decoder, stacked_ae\n",
    "\n",
    "# stacked_encoder, stacked_decoder, model = create_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2eb91f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 125 samples, validate on 113 samples\n",
      "Epoch 1/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\eller\\anaconda3\\envs\\IC\\lib\\site-packages\\keras\\engine\\training.py:2470: UserWarning: `Model.state_updates` will be removed in a future version. This property should not be used in TensorFlow 2.0, as `updates` are applied automatically.\n",
      "  warnings.warn('`Model.state_updates` will be removed in a future version. '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "125/125 - 4s - loss: 0.7153 - val_loss: 0.6604\n",
      "Epoch 2/400\n",
      "125/125 - 0s - loss: 0.1874 - val_loss: 0.6158\n",
      "Epoch 3/400\n",
      "125/125 - 0s - loss: 0.0709 - val_loss: 0.5238\n",
      "Epoch 4/400\n",
      "125/125 - 0s - loss: 0.0579 - val_loss: 0.4399\n",
      "Epoch 5/400\n",
      "125/125 - 0s - loss: 0.0573 - val_loss: 0.3743\n",
      "Epoch 6/400\n",
      "125/125 - 0s - loss: 0.0368 - val_loss: 0.3284\n",
      "Epoch 7/400\n",
      "125/125 - 0s - loss: 0.0300 - val_loss: 0.3230\n",
      "Epoch 8/400\n",
      "125/125 - 0s - loss: 0.0274 - val_loss: 0.2919\n",
      "Epoch 9/400\n",
      "125/125 - 0s - loss: 0.0254 - val_loss: 0.2710\n",
      "Epoch 10/400\n",
      "125/125 - 0s - loss: 0.0241 - val_loss: 0.2442\n",
      "Epoch 11/400\n",
      "125/125 - 0s - loss: 0.0230 - val_loss: 0.2189\n",
      "Epoch 12/400\n",
      "125/125 - 0s - loss: 0.0222 - val_loss: 0.1972\n",
      "Epoch 13/400\n",
      "125/125 - 0s - loss: 0.0214 - val_loss: 0.1767\n",
      "Epoch 14/400\n",
      "125/125 - 0s - loss: 0.0208 - val_loss: 0.1574\n",
      "Epoch 15/400\n",
      "125/125 - 0s - loss: 0.0203 - val_loss: 0.1399\n",
      "Epoch 16/400\n",
      "125/125 - 0s - loss: 0.0198 - val_loss: 0.1242\n",
      "Epoch 17/400\n",
      "125/125 - 0s - loss: 0.0194 - val_loss: 0.1103\n",
      "Epoch 18/400\n",
      "125/125 - 0s - loss: 0.0190 - val_loss: 0.0971\n",
      "Epoch 19/400\n",
      "125/125 - 0s - loss: 0.0187 - val_loss: 0.0863\n",
      "Epoch 20/400\n",
      "125/125 - 0s - loss: 0.0185 - val_loss: 0.0763\n",
      "Epoch 21/400\n",
      "125/125 - 0s - loss: 0.0182 - val_loss: 0.0682\n",
      "Epoch 22/400\n",
      "125/125 - 0s - loss: 0.0180 - val_loss: 0.0612\n",
      "Epoch 23/400\n",
      "125/125 - 0s - loss: 0.0178 - val_loss: 0.0550\n",
      "Epoch 24/400\n",
      "125/125 - 0s - loss: 0.0176 - val_loss: 0.0508\n",
      "Epoch 25/400\n",
      "125/125 - 0s - loss: 0.0174 - val_loss: 0.0463\n",
      "Epoch 26/400\n",
      "125/125 - 0s - loss: 0.0172 - val_loss: 0.0427\n",
      "Epoch 27/400\n",
      "125/125 - 0s - loss: 0.0171 - val_loss: 0.0398\n",
      "Epoch 28/400\n",
      "125/125 - 0s - loss: 0.0169 - val_loss: 0.0367\n",
      "Epoch 29/400\n",
      "125/125 - 0s - loss: 0.0168 - val_loss: 0.0345\n",
      "Epoch 30/400\n",
      "125/125 - 0s - loss: 0.0167 - val_loss: 0.0332\n",
      "Epoch 31/400\n",
      "125/125 - 0s - loss: 0.0166 - val_loss: 0.0309\n",
      "Epoch 32/400\n",
      "125/125 - 0s - loss: 0.0165 - val_loss: 0.0303\n",
      "Epoch 33/400\n",
      "125/125 - 0s - loss: 0.0164 - val_loss: 0.0277\n",
      "Epoch 34/400\n",
      "125/125 - 0s - loss: 0.0163 - val_loss: 0.0286\n",
      "Epoch 35/400\n",
      "125/125 - 0s - loss: 0.0162 - val_loss: 0.0243\n",
      "Epoch 36/400\n",
      "125/125 - 0s - loss: 0.0161 - val_loss: 0.0270\n",
      "Epoch 37/400\n",
      "125/125 - 0s - loss: 0.0161 - val_loss: 0.0226\n",
      "Epoch 38/400\n",
      "125/125 - 0s - loss: 0.0160 - val_loss: 0.0253\n",
      "Epoch 39/400\n",
      "125/125 - 0s - loss: 0.0160 - val_loss: 0.0212\n",
      "Epoch 40/400\n",
      "125/125 - 0s - loss: 0.0159 - val_loss: 0.0244\n",
      "Epoch 41/400\n",
      "125/125 - 0s - loss: 0.0158 - val_loss: 0.0210\n",
      "Epoch 42/400\n",
      "125/125 - 0s - loss: 0.0158 - val_loss: 0.0230\n",
      "Epoch 43/400\n",
      "125/125 - 0s - loss: 0.0156 - val_loss: 0.0212\n",
      "Epoch 44/400\n",
      "125/125 - 0s - loss: 0.0155 - val_loss: 0.0226\n",
      "Epoch 45/400\n",
      "125/125 - 0s - loss: 0.0154 - val_loss: 0.0205\n",
      "Epoch 46/400\n",
      "125/125 - 0s - loss: 0.0153 - val_loss: 0.0228\n",
      "Epoch 47/400\n",
      "125/125 - 0s - loss: 0.0152 - val_loss: 0.0202\n",
      "Epoch 48/400\n",
      "125/125 - 0s - loss: 0.0153 - val_loss: 0.0217\n",
      "Epoch 49/400\n",
      "125/125 - 0s - loss: 0.0151 - val_loss: 0.0199\n",
      "Epoch 50/400\n",
      "125/125 - 0s - loss: 0.0151 - val_loss: 0.0207\n",
      "Epoch 51/400\n",
      "125/125 - 0s - loss: 0.0148 - val_loss: 0.0207\n",
      "Epoch 52/400\n",
      "125/125 - 0s - loss: 0.0148 - val_loss: 0.0199\n",
      "Epoch 53/400\n",
      "125/125 - 0s - loss: 0.0146 - val_loss: 0.0202\n",
      "Epoch 54/400\n",
      "125/125 - 0s - loss: 0.0146 - val_loss: 0.0194\n",
      "Epoch 55/400\n",
      "125/125 - 0s - loss: 0.0143 - val_loss: 0.0196\n",
      "Epoch 56/400\n",
      "125/125 - 0s - loss: 0.0143 - val_loss: 0.0192\n",
      "Epoch 57/400\n",
      "125/125 - 0s - loss: 0.0141 - val_loss: 0.0198\n",
      "Epoch 58/400\n",
      "125/125 - 0s - loss: 0.0141 - val_loss: 0.0193\n",
      "Epoch 59/400\n",
      "125/125 - 0s - loss: 0.0139 - val_loss: 0.0198\n",
      "Epoch 60/400\n",
      "125/125 - 0s - loss: 0.0139 - val_loss: 0.0193\n",
      "Epoch 61/400\n",
      "125/125 - 0s - loss: 0.0137 - val_loss: 0.0192\n",
      "Epoch 62/400\n",
      "125/125 - 0s - loss: 0.0135 - val_loss: 0.0193\n",
      "Epoch 63/400\n",
      "125/125 - 0s - loss: 0.0134 - val_loss: 0.0194\n",
      "Epoch 64/400\n",
      "125/125 - 0s - loss: 0.0132 - val_loss: 0.0194\n",
      "Epoch 65/400\n",
      "125/125 - 0s - loss: 0.0132 - val_loss: 0.0194\n",
      "Epoch 66/400\n",
      "125/125 - 0s - loss: 0.0131 - val_loss: 0.0201\n",
      "Epoch 67/400\n",
      "125/125 - 0s - loss: 0.0133 - val_loss: 0.0196\n",
      "Epoch 68/400\n",
      "125/125 - 0s - loss: 0.0129 - val_loss: 0.0197\n",
      "Epoch 69/400\n",
      "125/125 - 0s - loss: 0.0128 - val_loss: 0.0195\n",
      "Epoch 70/400\n",
      "125/125 - 0s - loss: 0.0127 - val_loss: 0.0194\n",
      "Epoch 71/400\n",
      "125/125 - 0s - loss: 0.0124 - val_loss: 0.0194\n",
      "Epoch 72/400\n",
      "125/125 - 0s - loss: 0.0122 - val_loss: 0.0194\n",
      "Epoch 73/400\n",
      "125/125 - 0s - loss: 0.0119 - val_loss: 0.0196\n",
      "Epoch 74/400\n",
      "125/125 - 0s - loss: 0.0121 - val_loss: 0.0201\n",
      "Epoch 75/400\n",
      "125/125 - 0s - loss: 0.0120 - val_loss: 0.0197\n",
      "Epoch 76/400\n",
      "125/125 - 0s - loss: 0.0119 - val_loss: 0.0190\n",
      "Epoch 77/400\n",
      "125/125 - 0s - loss: 0.0114 - val_loss: 0.0192\n",
      "Epoch 78/400\n",
      "125/125 - 0s - loss: 0.0112 - val_loss: 0.0188\n",
      "Epoch 79/400\n",
      "125/125 - 0s - loss: 0.0110 - val_loss: 0.0197\n",
      "Epoch 80/400\n",
      "125/125 - 0s - loss: 0.0112 - val_loss: 0.0194\n",
      "Epoch 81/400\n",
      "125/125 - 0s - loss: 0.0111 - val_loss: 0.0204\n",
      "Epoch 82/400\n",
      "125/125 - 0s - loss: 0.0111 - val_loss: 0.0187\n",
      "Epoch 83/400\n",
      "125/125 - 1s - loss: 0.0105 - val_loss: 0.0195\n",
      "Epoch 84/400\n",
      "125/125 - 0s - loss: 0.0103 - val_loss: 0.0190\n",
      "Epoch 85/400\n",
      "125/125 - 1s - loss: 0.0099 - val_loss: 0.0198\n",
      "Epoch 86/400\n",
      "125/125 - 0s - loss: 0.0099 - val_loss: 0.0191\n",
      "Epoch 87/400\n",
      "125/125 - 0s - loss: 0.0098 - val_loss: 0.0193\n",
      "Epoch 88/400\n",
      "125/125 - 0s - loss: 0.0097 - val_loss: 0.0190\n",
      "Epoch 89/400\n",
      "125/125 - 0s - loss: 0.0094 - val_loss: 0.0191\n",
      "Epoch 90/400\n",
      "125/125 - 0s - loss: 0.0092 - val_loss: 0.0190\n",
      "Epoch 91/400\n",
      "125/125 - 0s - loss: 0.0090 - val_loss: 0.0197\n",
      "Epoch 92/400\n",
      "125/125 - 0s - loss: 0.0091 - val_loss: 0.0195\n",
      "Epoch 93/400\n",
      "125/125 - 0s - loss: 0.0090 - val_loss: 0.0196\n",
      "Epoch 94/400\n",
      "125/125 - 0s - loss: 0.0089 - val_loss: 0.0188\n",
      "Epoch 95/400\n",
      "125/125 - 0s - loss: 0.0083 - val_loss: 0.0193\n",
      "Epoch 96/400\n",
      "125/125 - 0s - loss: 0.0081 - val_loss: 0.0186\n",
      "Epoch 97/400\n",
      "125/125 - 0s - loss: 0.0079 - val_loss: 0.0196\n",
      "Epoch 98/400\n",
      "125/125 - 1s - loss: 0.0079 - val_loss: 0.0185\n",
      "Epoch 99/400\n",
      "125/125 - 1s - loss: 0.0078 - val_loss: 0.0202\n",
      "Epoch 100/400\n",
      "125/125 - 0s - loss: 0.0077 - val_loss: 0.0186\n",
      "Epoch 101/400\n",
      "125/125 - 0s - loss: 0.0075 - val_loss: 0.0197\n",
      "Epoch 102/400\n",
      "125/125 - 0s - loss: 0.0074 - val_loss: 0.0186\n",
      "Epoch 103/400\n",
      "125/125 - 0s - loss: 0.0071 - val_loss: 0.0195\n",
      "Epoch 104/400\n",
      "125/125 - 0s - loss: 0.0070 - val_loss: 0.0188\n",
      "Epoch 105/400\n",
      "125/125 - 0s - loss: 0.0069 - val_loss: 0.0189\n",
      "Epoch 106/400\n",
      "125/125 - 0s - loss: 0.0068 - val_loss: 0.0190\n",
      "Epoch 107/400\n",
      "125/125 - 0s - loss: 0.0066 - val_loss: 0.0189\n",
      "Epoch 108/400\n",
      "125/125 - 0s - loss: 0.0064 - val_loss: 0.0191\n",
      "Epoch 109/400\n",
      "125/125 - 0s - loss: 0.0062 - val_loss: 0.0193\n",
      "Epoch 110/400\n",
      "125/125 - 0s - loss: 0.0061 - val_loss: 0.0194\n",
      "Epoch 111/400\n",
      "125/125 - 0s - loss: 0.0061 - val_loss: 0.0196\n",
      "Epoch 112/400\n",
      "125/125 - 0s - loss: 0.0060 - val_loss: 0.0196\n",
      "Epoch 113/400\n",
      "125/125 - 0s - loss: 0.0059 - val_loss: 0.0194\n",
      "Epoch 114/400\n",
      "125/125 - 0s - loss: 0.0056 - val_loss: 0.0193\n",
      "Epoch 115/400\n",
      "125/125 - 0s - loss: 0.0055 - val_loss: 0.0194\n",
      "Epoch 116/400\n",
      "125/125 - 0s - loss: 0.0054 - val_loss: 0.0199\n",
      "Epoch 117/400\n",
      "125/125 - 0s - loss: 0.0053 - val_loss: 0.0193\n",
      "Epoch 118/400\n",
      "125/125 - 0s - loss: 0.0052 - val_loss: 0.0199\n",
      "Epoch 119/400\n",
      "125/125 - 0s - loss: 0.0051 - val_loss: 0.0194\n",
      "Epoch 120/400\n",
      "125/125 - 0s - loss: 0.0050 - val_loss: 0.0197\n",
      "Epoch 121/400\n",
      "125/125 - 0s - loss: 0.0048 - val_loss: 0.0196\n",
      "Epoch 122/400\n",
      "125/125 - 0s - loss: 0.0047 - val_loss: 0.0196\n",
      "Epoch 123/400\n",
      "125/125 - 0s - loss: 0.0045 - val_loss: 0.0198\n",
      "Epoch 124/400\n",
      "125/125 - 0s - loss: 0.0045 - val_loss: 0.0200\n",
      "Epoch 125/400\n",
      "125/125 - 0s - loss: 0.0044 - val_loss: 0.0203\n",
      "Epoch 126/400\n",
      "125/125 - 0s - loss: 0.0043 - val_loss: 0.0202\n",
      "Epoch 127/400\n",
      "125/125 - 0s - loss: 0.0042 - val_loss: 0.0202\n",
      "Epoch 128/400\n",
      "125/125 - 0s - loss: 0.0041 - val_loss: 0.0200\n",
      "Epoch 129/400\n",
      "125/125 - 0s - loss: 0.0040 - val_loss: 0.0204\n",
      "Epoch 130/400\n",
      "125/125 - 0s - loss: 0.0040 - val_loss: 0.0197\n",
      "Epoch 131/400\n",
      "125/125 - 0s - loss: 0.0039 - val_loss: 0.0208\n",
      "Epoch 132/400\n",
      "125/125 - 0s - loss: 0.0038 - val_loss: 0.0200\n",
      "Epoch 133/400\n",
      "125/125 - 0s - loss: 0.0038 - val_loss: 0.0205\n",
      "Epoch 134/400\n",
      "125/125 - 0s - loss: 0.0036 - val_loss: 0.0202\n",
      "Epoch 135/400\n",
      "125/125 - 0s - loss: 0.0035 - val_loss: 0.0202\n",
      "Epoch 136/400\n",
      "125/125 - 0s - loss: 0.0034 - val_loss: 0.0203\n",
      "Epoch 137/400\n",
      "125/125 - 0s - loss: 0.0033 - val_loss: 0.0206\n",
      "Epoch 138/400\n",
      "125/125 - 0s - loss: 0.0032 - val_loss: 0.0204\n",
      "Epoch 139/400\n",
      "125/125 - 0s - loss: 0.0032 - val_loss: 0.0208\n",
      "Epoch 140/400\n",
      "125/125 - 0s - loss: 0.0031 - val_loss: 0.0206\n",
      "Epoch 141/400\n",
      "125/125 - 0s - loss: 0.0030 - val_loss: 0.0209\n",
      "Epoch 142/400\n",
      "125/125 - 0s - loss: 0.0030 - val_loss: 0.0210\n",
      "Epoch 143/400\n",
      "125/125 - 0s - loss: 0.0029 - val_loss: 0.0213\n",
      "Epoch 144/400\n",
      "125/125 - 0s - loss: 0.0029 - val_loss: 0.0208\n",
      "Epoch 145/400\n",
      "125/125 - 0s - loss: 0.0028 - val_loss: 0.0215\n",
      "Epoch 146/400\n",
      "125/125 - 0s - loss: 0.0027 - val_loss: 0.0210\n",
      "Epoch 147/400\n",
      "125/125 - 0s - loss: 0.0027 - val_loss: 0.0212\n",
      "Epoch 148/400\n",
      "125/125 - 0s - loss: 0.0026 - val_loss: 0.0213\n",
      "Epoch 149/400\n",
      "125/125 - 0s - loss: 0.0025 - val_loss: 0.0213\n",
      "Epoch 150/400\n",
      "125/125 - 0s - loss: 0.0025 - val_loss: 0.0211\n",
      "Epoch 151/400\n",
      "125/125 - 0s - loss: 0.0025 - val_loss: 0.0217\n",
      "Epoch 152/400\n",
      "125/125 - 0s - loss: 0.0024 - val_loss: 0.0210\n",
      "Epoch 153/400\n",
      "125/125 - 0s - loss: 0.0024 - val_loss: 0.0216\n",
      "Epoch 154/400\n",
      "125/125 - 0s - loss: 0.0023 - val_loss: 0.0213\n",
      "Epoch 155/400\n",
      "125/125 - 0s - loss: 0.0023 - val_loss: 0.0215\n",
      "Epoch 156/400\n",
      "125/125 - 0s - loss: 0.0022 - val_loss: 0.0216\n",
      "Epoch 157/400\n",
      "125/125 - 0s - loss: 0.0021 - val_loss: 0.0218\n",
      "Epoch 158/400\n",
      "125/125 - 0s - loss: 0.0021 - val_loss: 0.0216\n",
      "Epoch 159/400\n",
      "125/125 - 0s - loss: 0.0020 - val_loss: 0.0220\n",
      "Epoch 160/400\n",
      "125/125 - 0s - loss: 0.0020 - val_loss: 0.0217\n",
      "Epoch 161/400\n",
      "125/125 - 0s - loss: 0.0019 - val_loss: 0.0220\n",
      "Epoch 162/400\n",
      "125/125 - 0s - loss: 0.0018 - val_loss: 0.0218\n",
      "Epoch 163/400\n",
      "125/125 - 0s - loss: 0.0018 - val_loss: 0.0218\n",
      "Epoch 164/400\n",
      "125/125 - 0s - loss: 0.0018 - val_loss: 0.0221\n",
      "Epoch 165/400\n",
      "125/125 - 0s - loss: 0.0017 - val_loss: 0.0219\n",
      "Epoch 166/400\n",
      "125/125 - 0s - loss: 0.0017 - val_loss: 0.0224\n",
      "Epoch 167/400\n",
      "125/125 - 0s - loss: 0.0017 - val_loss: 0.0220\n",
      "Epoch 168/400\n",
      "125/125 - 0s - loss: 0.0016 - val_loss: 0.0225\n",
      "Epoch 169/400\n",
      "125/125 - 0s - loss: 0.0016 - val_loss: 0.0223\n",
      "Epoch 170/400\n",
      "125/125 - 0s - loss: 0.0016 - val_loss: 0.0225\n",
      "Epoch 171/400\n",
      "125/125 - 0s - loss: 0.0015 - val_loss: 0.0226\n",
      "Epoch 172/400\n",
      "125/125 - 0s - loss: 0.0015 - val_loss: 0.0225\n",
      "Epoch 173/400\n",
      "125/125 - 0s - loss: 0.0014 - val_loss: 0.0228\n",
      "Epoch 174/400\n",
      "125/125 - 0s - loss: 0.0014 - val_loss: 0.0227\n",
      "Epoch 175/400\n",
      "125/125 - 0s - loss: 0.0014 - val_loss: 0.0231\n",
      "Epoch 176/400\n",
      "125/125 - 0s - loss: 0.0013 - val_loss: 0.0229\n",
      "Epoch 177/400\n",
      "125/125 - 0s - loss: 0.0013 - val_loss: 0.0230\n",
      "Epoch 178/400\n",
      "125/125 - 0s - loss: 0.0013 - val_loss: 0.0230\n",
      "Epoch 179/400\n",
      "125/125 - 0s - loss: 0.0013 - val_loss: 0.0227\n",
      "Epoch 180/400\n",
      "125/125 - 0s - loss: 0.0013 - val_loss: 0.0235\n",
      "Epoch 181/400\n",
      "125/125 - 0s - loss: 0.0012 - val_loss: 0.0224\n",
      "Epoch 182/400\n",
      "125/125 - 0s - loss: 0.0012 - val_loss: 0.0235\n",
      "Epoch 183/400\n",
      "125/125 - 0s - loss: 0.0011 - val_loss: 0.0227\n",
      "Epoch 184/400\n",
      "125/125 - 0s - loss: 0.0011 - val_loss: 0.0233\n",
      "Epoch 185/400\n",
      "125/125 - 0s - loss: 0.0011 - val_loss: 0.0228\n",
      "Epoch 186/400\n",
      "125/125 - 0s - loss: 0.0011 - val_loss: 0.0233\n",
      "Epoch 187/400\n",
      "125/125 - 0s - loss: 0.0010 - val_loss: 0.0229\n",
      "Epoch 188/400\n",
      "125/125 - 0s - loss: 0.0011 - val_loss: 0.0231\n",
      "Epoch 189/400\n",
      "125/125 - 0s - loss: 0.0011 - val_loss: 0.0239\n",
      "Epoch 190/400\n",
      "125/125 - 0s - loss: 0.0012 - val_loss: 0.0236\n",
      "Epoch 191/400\n",
      "125/125 - 0s - loss: 0.0012 - val_loss: 0.0272\n",
      "Epoch 192/400\n",
      "125/125 - 0s - loss: 0.0016 - val_loss: 0.0254\n",
      "Epoch 193/400\n",
      "125/125 - 0s - loss: 0.0016 - val_loss: 0.0252\n",
      "Epoch 194/400\n",
      "125/125 - 0s - loss: 0.0014 - val_loss: 0.0230\n",
      "Epoch 195/400\n",
      "125/125 - 0s - loss: 0.0017 - val_loss: 0.0247\n",
      "Epoch 196/400\n",
      "125/125 - 0s - loss: 0.0013 - val_loss: 0.0222\n",
      "Epoch 197/400\n",
      "125/125 - 0s - loss: 9.9671e-04 - val_loss: 0.0231\n",
      "Epoch 198/400\n",
      "125/125 - 0s - loss: 8.8766e-04 - val_loss: 0.0229\n",
      "Epoch 199/400\n",
      "125/125 - 0s - loss: 8.3491e-04 - val_loss: 0.0232\n",
      "Epoch 200/400\n",
      "125/125 - 0s - loss: 7.9030e-04 - val_loss: 0.0233\n",
      "Epoch 201/400\n",
      "125/125 - 0s - loss: 7.6683e-04 - val_loss: 0.0235\n",
      "Epoch 202/400\n",
      "125/125 - 0s - loss: 7.4160e-04 - val_loss: 0.0238\n",
      "Epoch 203/400\n",
      "125/125 - 0s - loss: 7.4157e-04 - val_loss: 0.0239\n",
      "Epoch 204/400\n",
      "125/125 - 0s - loss: 7.1242e-04 - val_loss: 0.0240\n",
      "Epoch 205/400\n",
      "125/125 - 0s - loss: 6.9712e-04 - val_loss: 0.0241\n",
      "Epoch 206/400\n",
      "125/125 - 0s - loss: 6.9522e-04 - val_loss: 0.0241\n",
      "Epoch 207/400\n",
      "125/125 - 0s - loss: 6.8519e-04 - val_loss: 0.0243\n",
      "Epoch 208/400\n",
      "125/125 - 0s - loss: 6.7754e-04 - val_loss: 0.0244\n",
      "Epoch 209/400\n",
      "125/125 - 0s - loss: 6.5584e-04 - val_loss: 0.0246\n",
      "Epoch 210/400\n",
      "125/125 - 0s - loss: 6.5159e-04 - val_loss: 0.0243\n",
      "Epoch 211/400\n",
      "125/125 - 0s - loss: 6.3631e-04 - val_loss: 0.0248\n",
      "Epoch 212/400\n",
      "125/125 - 0s - loss: 6.1910e-04 - val_loss: 0.0250\n",
      "Epoch 213/400\n",
      "125/125 - 0s - loss: 6.1413e-04 - val_loss: 0.0249\n",
      "Epoch 214/400\n",
      "125/125 - 1s - loss: 6.1148e-04 - val_loss: 0.0251\n",
      "Epoch 215/400\n",
      "125/125 - 0s - loss: 5.9789e-04 - val_loss: 0.0249\n",
      "Epoch 216/400\n",
      "125/125 - 0s - loss: 5.8427e-04 - val_loss: 0.0255\n",
      "Epoch 217/400\n",
      "125/125 - 0s - loss: 5.6857e-04 - val_loss: 0.0253\n",
      "Epoch 218/400\n",
      "125/125 - 0s - loss: 5.7541e-04 - val_loss: 0.0255\n",
      "Epoch 219/400\n",
      "125/125 - 0s - loss: 5.7264e-04 - val_loss: 0.0252\n",
      "Epoch 220/400\n",
      "125/125 - 0s - loss: 5.6036e-04 - val_loss: 0.0255\n",
      "Epoch 221/400\n",
      "125/125 - 0s - loss: 5.4126e-04 - val_loss: 0.0253\n",
      "Epoch 222/400\n",
      "125/125 - 0s - loss: 5.2479e-04 - val_loss: 0.0257\n",
      "Epoch 223/400\n",
      "125/125 - 0s - loss: 5.2734e-04 - val_loss: 0.0256\n",
      "Epoch 224/400\n",
      "125/125 - 0s - loss: 5.0927e-04 - val_loss: 0.0257\n",
      "Epoch 225/400\n",
      "125/125 - 0s - loss: 4.9690e-04 - val_loss: 0.0257\n",
      "Epoch 226/400\n",
      "125/125 - 0s - loss: 4.8744e-04 - val_loss: 0.0255\n",
      "Epoch 227/400\n",
      "125/125 - 0s - loss: 4.7987e-04 - val_loss: 0.0259\n",
      "Epoch 228/400\n",
      "125/125 - 0s - loss: 4.8500e-04 - val_loss: 0.0259\n",
      "Epoch 229/400\n",
      "125/125 - 0s - loss: 4.6569e-04 - val_loss: 0.0259\n",
      "Epoch 230/400\n",
      "125/125 - 0s - loss: 4.5559e-04 - val_loss: 0.0258\n",
      "Epoch 231/400\n",
      "125/125 - 0s - loss: 4.5484e-04 - val_loss: 0.0257\n",
      "Epoch 232/400\n",
      "125/125 - 0s - loss: 4.4323e-04 - val_loss: 0.0258\n",
      "Epoch 233/400\n",
      "125/125 - 0s - loss: 4.3159e-04 - val_loss: 0.0260\n",
      "Epoch 234/400\n",
      "125/125 - 0s - loss: 4.2627e-04 - val_loss: 0.0262\n",
      "Epoch 235/400\n",
      "125/125 - 0s - loss: 4.3101e-04 - val_loss: 0.0255\n",
      "Epoch 236/400\n",
      "125/125 - 0s - loss: 4.2008e-04 - val_loss: 0.0262\n",
      "Epoch 237/400\n",
      "125/125 - 0s - loss: 4.0765e-04 - val_loss: 0.0262\n",
      "Epoch 238/400\n",
      "125/125 - 0s - loss: 4.0522e-04 - val_loss: 0.0259\n",
      "Epoch 239/400\n",
      "125/125 - 0s - loss: 3.9085e-04 - val_loss: 0.0257\n",
      "Epoch 240/400\n",
      "125/125 - 0s - loss: 3.9653e-04 - val_loss: 0.0261\n",
      "Epoch 241/400\n",
      "125/125 - 0s - loss: 3.8636e-04 - val_loss: 0.0261\n",
      "Epoch 242/400\n",
      "125/125 - 0s - loss: 3.7478e-04 - val_loss: 0.0263\n",
      "Epoch 243/400\n",
      "125/125 - 0s - loss: 3.8144e-04 - val_loss: 0.0258\n",
      "Epoch 244/400\n",
      "125/125 - 0s - loss: 3.8347e-04 - val_loss: 0.0265\n",
      "Epoch 245/400\n",
      "125/125 - 0s - loss: 3.6345e-04 - val_loss: 0.0260\n",
      "Epoch 246/400\n",
      "125/125 - 0s - loss: 3.6341e-04 - val_loss: 0.0263\n",
      "Epoch 247/400\n",
      "125/125 - 0s - loss: 3.4589e-04 - val_loss: 0.0264\n",
      "Epoch 248/400\n",
      "125/125 - 0s - loss: 3.4601e-04 - val_loss: 0.0265\n",
      "Epoch 249/400\n",
      "125/125 - 0s - loss: 3.4258e-04 - val_loss: 0.0261\n",
      "Epoch 250/400\n",
      "125/125 - 0s - loss: 3.2915e-04 - val_loss: 0.0266\n",
      "Epoch 251/400\n",
      "125/125 - 0s - loss: 3.4452e-04 - val_loss: 0.0260\n",
      "Epoch 252/400\n",
      "125/125 - 0s - loss: 3.2717e-04 - val_loss: 0.0265\n",
      "Epoch 253/400\n",
      "125/125 - 0s - loss: 3.3019e-04 - val_loss: 0.0260\n",
      "Epoch 254/400\n",
      "125/125 - 0s - loss: 3.3868e-04 - val_loss: 0.0269\n",
      "Epoch 255/400\n",
      "125/125 - 0s - loss: 3.2677e-04 - val_loss: 0.0264\n",
      "Epoch 256/400\n",
      "125/125 - 0s - loss: 3.1191e-04 - val_loss: 0.0267\n",
      "Epoch 257/400\n",
      "125/125 - 0s - loss: 3.0464e-04 - val_loss: 0.0263\n",
      "Epoch 258/400\n",
      "125/125 - 0s - loss: 2.9811e-04 - val_loss: 0.0267\n",
      "Epoch 259/400\n",
      "125/125 - 0s - loss: 3.0219e-04 - val_loss: 0.0263\n",
      "Epoch 260/400\n",
      "125/125 - 0s - loss: 2.8732e-04 - val_loss: 0.0265\n",
      "Epoch 261/400\n",
      "125/125 - 0s - loss: 2.8861e-04 - val_loss: 0.0264\n",
      "Epoch 262/400\n",
      "125/125 - 0s - loss: 2.8426e-04 - val_loss: 0.0267\n",
      "Epoch 263/400\n",
      "125/125 - 0s - loss: 2.7556e-04 - val_loss: 0.0264\n",
      "Epoch 264/400\n",
      "125/125 - 0s - loss: 2.8450e-04 - val_loss: 0.0265\n",
      "Epoch 265/400\n",
      "125/125 - 0s - loss: 2.7185e-04 - val_loss: 0.0266\n",
      "Epoch 266/400\n",
      "125/125 - 0s - loss: 2.6376e-04 - val_loss: 0.0265\n",
      "Epoch 267/400\n",
      "125/125 - 0s - loss: 2.6656e-04 - val_loss: 0.0266\n",
      "Epoch 268/400\n",
      "125/125 - 0s - loss: 2.6324e-04 - val_loss: 0.0267\n",
      "Epoch 269/400\n",
      "125/125 - 0s - loss: 2.5558e-04 - val_loss: 0.0264\n",
      "Epoch 270/400\n",
      "125/125 - 0s - loss: 2.6606e-04 - val_loss: 0.0268\n",
      "Epoch 271/400\n",
      "125/125 - 0s - loss: 2.5253e-04 - val_loss: 0.0269\n",
      "Epoch 272/400\n",
      "125/125 - 0s - loss: 2.5127e-04 - val_loss: 0.0264\n",
      "Epoch 273/400\n",
      "125/125 - 0s - loss: 2.4857e-04 - val_loss: 0.0266\n",
      "Epoch 274/400\n",
      "125/125 - 0s - loss: 2.4167e-04 - val_loss: 0.0272\n",
      "Epoch 275/400\n",
      "125/125 - 0s - loss: 2.3951e-04 - val_loss: 0.0270\n",
      "Epoch 276/400\n",
      "125/125 - 0s - loss: 2.4011e-04 - val_loss: 0.0269\n",
      "Epoch 277/400\n",
      "125/125 - 1s - loss: 2.3980e-04 - val_loss: 0.0269\n",
      "Epoch 278/400\n",
      "125/125 - 0s - loss: 2.3129e-04 - val_loss: 0.0268\n",
      "Epoch 279/400\n",
      "125/125 - 0s - loss: 2.2685e-04 - val_loss: 0.0270\n",
      "Epoch 280/400\n",
      "125/125 - 0s - loss: 2.3415e-04 - val_loss: 0.0269\n",
      "Epoch 281/400\n",
      "125/125 - 1s - loss: 2.3715e-04 - val_loss: 0.0270\n",
      "Epoch 282/400\n",
      "125/125 - 0s - loss: 2.3097e-04 - val_loss: 0.0267\n",
      "Epoch 283/400\n",
      "125/125 - 0s - loss: 2.2245e-04 - val_loss: 0.0270\n",
      "Epoch 284/400\n",
      "125/125 - 0s - loss: 2.1485e-04 - val_loss: 0.0270\n",
      "Epoch 285/400\n",
      "125/125 - 0s - loss: 2.2370e-04 - val_loss: 0.0267\n",
      "Epoch 286/400\n",
      "125/125 - 0s - loss: 2.1863e-04 - val_loss: 0.0267\n",
      "Epoch 287/400\n",
      "125/125 - 1s - loss: 2.0527e-04 - val_loss: 0.0269\n",
      "Epoch 288/400\n",
      "125/125 - 1s - loss: 2.0517e-04 - val_loss: 0.0269\n",
      "Epoch 289/400\n",
      "125/125 - 0s - loss: 2.0870e-04 - val_loss: 0.0265\n",
      "Epoch 290/400\n",
      "125/125 - 0s - loss: 2.1412e-04 - val_loss: 0.0269\n",
      "Epoch 291/400\n",
      "125/125 - 0s - loss: 2.0689e-04 - val_loss: 0.0273\n",
      "Epoch 292/400\n",
      "125/125 - 0s - loss: 2.1025e-04 - val_loss: 0.0274\n",
      "Epoch 293/400\n",
      "125/125 - 0s - loss: 1.9547e-04 - val_loss: 0.0270\n",
      "Epoch 294/400\n",
      "125/125 - 0s - loss: 1.9711e-04 - val_loss: 0.0271\n",
      "Epoch 295/400\n",
      "125/125 - 0s - loss: 2.0317e-04 - val_loss: 0.0268\n",
      "Epoch 296/400\n",
      "125/125 - 0s - loss: 2.0112e-04 - val_loss: 0.0268\n",
      "Epoch 297/400\n",
      "125/125 - 0s - loss: 1.8965e-04 - val_loss: 0.0274\n",
      "Epoch 298/400\n",
      "125/125 - 0s - loss: 1.9015e-04 - val_loss: 0.0272\n",
      "Epoch 299/400\n",
      "125/125 - 0s - loss: 1.8736e-04 - val_loss: 0.0268\n",
      "Epoch 300/400\n",
      "125/125 - 0s - loss: 1.8437e-04 - val_loss: 0.0272\n",
      "Epoch 301/400\n",
      "125/125 - 0s - loss: 1.8148e-04 - val_loss: 0.0271\n",
      "Epoch 302/400\n",
      "125/125 - 0s - loss: 1.8301e-04 - val_loss: 0.0272\n",
      "Epoch 303/400\n",
      "125/125 - 0s - loss: 1.8549e-04 - val_loss: 0.0273\n",
      "Epoch 304/400\n",
      "125/125 - 0s - loss: 1.7842e-04 - val_loss: 0.0270\n",
      "Epoch 305/400\n",
      "125/125 - 0s - loss: 1.7972e-04 - val_loss: 0.0271\n",
      "Epoch 306/400\n",
      "125/125 - 0s - loss: 1.8363e-04 - val_loss: 0.0272\n",
      "Epoch 307/400\n",
      "125/125 - 0s - loss: 1.7788e-04 - val_loss: 0.0270\n",
      "Epoch 308/400\n",
      "125/125 - 0s - loss: 1.6971e-04 - val_loss: 0.0271\n",
      "Epoch 309/400\n",
      "125/125 - 0s - loss: 1.6805e-04 - val_loss: 0.0275\n",
      "Epoch 310/400\n",
      "125/125 - 0s - loss: 1.6969e-04 - val_loss: 0.0270\n",
      "Epoch 311/400\n",
      "125/125 - 0s - loss: 1.6244e-04 - val_loss: 0.0272\n",
      "Epoch 312/400\n",
      "125/125 - 0s - loss: 1.5982e-04 - val_loss: 0.0274\n",
      "Epoch 313/400\n",
      "125/125 - 0s - loss: 1.5943e-04 - val_loss: 0.0276\n",
      "Epoch 314/400\n",
      "125/125 - 0s - loss: 1.7027e-04 - val_loss: 0.0272\n",
      "Epoch 315/400\n",
      "125/125 - 0s - loss: 1.5949e-04 - val_loss: 0.0274\n",
      "Epoch 316/400\n",
      "125/125 - 0s - loss: 1.5957e-04 - val_loss: 0.0273\n",
      "Epoch 317/400\n",
      "125/125 - 0s - loss: 1.5642e-04 - val_loss: 0.0276\n",
      "Epoch 318/400\n",
      "125/125 - 0s - loss: 1.5463e-04 - val_loss: 0.0274\n",
      "Epoch 319/400\n",
      "125/125 - 0s - loss: 1.5756e-04 - val_loss: 0.0274\n",
      "Epoch 320/400\n",
      "125/125 - 0s - loss: 1.5610e-04 - val_loss: 0.0274\n",
      "Epoch 321/400\n",
      "125/125 - 0s - loss: 1.5407e-04 - val_loss: 0.0275\n",
      "Epoch 322/400\n",
      "125/125 - 0s - loss: 1.5042e-04 - val_loss: 0.0274\n",
      "Epoch 323/400\n",
      "125/125 - 0s - loss: 1.4888e-04 - val_loss: 0.0277\n",
      "Epoch 324/400\n",
      "125/125 - 0s - loss: 1.5165e-04 - val_loss: 0.0276\n",
      "Epoch 325/400\n",
      "125/125 - 1s - loss: 1.5008e-04 - val_loss: 0.0276\n",
      "Epoch 326/400\n",
      "125/125 - 1s - loss: 1.5131e-04 - val_loss: 0.0275\n",
      "Epoch 327/400\n",
      "125/125 - 1s - loss: 1.4682e-04 - val_loss: 0.0276\n",
      "Epoch 328/400\n",
      "125/125 - 0s - loss: 1.4250e-04 - val_loss: 0.0273\n",
      "Epoch 329/400\n",
      "125/125 - 0s - loss: 1.4455e-04 - val_loss: 0.0278\n",
      "Epoch 330/400\n",
      "125/125 - 0s - loss: 1.4960e-04 - val_loss: 0.0280\n",
      "Epoch 331/400\n",
      "125/125 - 0s - loss: 1.4328e-04 - val_loss: 0.0276\n",
      "Epoch 332/400\n",
      "125/125 - 0s - loss: 1.3827e-04 - val_loss: 0.0279\n",
      "Epoch 333/400\n",
      "125/125 - 0s - loss: 1.4034e-04 - val_loss: 0.0278\n",
      "Epoch 334/400\n",
      "125/125 - 0s - loss: 1.3350e-04 - val_loss: 0.0277\n",
      "Epoch 335/400\n",
      "125/125 - 0s - loss: 1.3702e-04 - val_loss: 0.0278\n",
      "Epoch 336/400\n",
      "125/125 - 0s - loss: 1.3629e-04 - val_loss: 0.0276\n",
      "Epoch 337/400\n",
      "125/125 - 0s - loss: 1.3105e-04 - val_loss: 0.0277\n",
      "Epoch 338/400\n",
      "125/125 - 0s - loss: 1.3424e-04 - val_loss: 0.0277\n",
      "Epoch 339/400\n",
      "125/125 - 0s - loss: 1.3512e-04 - val_loss: 0.0277\n",
      "Epoch 340/400\n",
      "125/125 - 0s - loss: 1.3185e-04 - val_loss: 0.0277\n",
      "Epoch 341/400\n",
      "125/125 - 0s - loss: 1.3413e-04 - val_loss: 0.0276\n",
      "Epoch 342/400\n",
      "125/125 - 0s - loss: 1.3097e-04 - val_loss: 0.0276\n",
      "Epoch 343/400\n",
      "125/125 - 0s - loss: 1.2749e-04 - val_loss: 0.0277\n",
      "Epoch 344/400\n",
      "125/125 - 0s - loss: 1.3116e-04 - val_loss: 0.0278\n",
      "Epoch 345/400\n",
      "125/125 - 0s - loss: 1.2594e-04 - val_loss: 0.0280\n",
      "Epoch 346/400\n",
      "125/125 - 1s - loss: 1.2098e-04 - val_loss: 0.0276\n",
      "Epoch 347/400\n",
      "125/125 - 0s - loss: 1.2620e-04 - val_loss: 0.0274\n",
      "Epoch 348/400\n",
      "125/125 - 0s - loss: 1.2045e-04 - val_loss: 0.0275\n",
      "Epoch 349/400\n",
      "125/125 - 0s - loss: 1.2416e-04 - val_loss: 0.0279\n",
      "Epoch 350/400\n",
      "125/125 - 0s - loss: 1.2165e-04 - val_loss: 0.0279\n",
      "Epoch 351/400\n",
      "125/125 - 0s - loss: 1.1896e-04 - val_loss: 0.0280\n",
      "Epoch 352/400\n",
      "125/125 - 0s - loss: 1.2335e-04 - val_loss: 0.0278\n",
      "Epoch 353/400\n",
      "125/125 - 0s - loss: 1.2034e-04 - val_loss: 0.0282\n",
      "Epoch 354/400\n",
      "125/125 - 0s - loss: 1.1990e-04 - val_loss: 0.0283\n",
      "Epoch 355/400\n",
      "125/125 - 0s - loss: 1.1547e-04 - val_loss: 0.0280\n",
      "Epoch 356/400\n",
      "125/125 - 0s - loss: 1.1369e-04 - val_loss: 0.0279\n",
      "Epoch 357/400\n",
      "125/125 - 0s - loss: 1.1785e-04 - val_loss: 0.0280\n",
      "Epoch 358/400\n",
      "125/125 - 0s - loss: 1.1660e-04 - val_loss: 0.0281\n",
      "Epoch 359/400\n",
      "125/125 - 0s - loss: 1.1466e-04 - val_loss: 0.0281\n",
      "Epoch 360/400\n",
      "125/125 - 0s - loss: 1.0875e-04 - val_loss: 0.0283\n",
      "Epoch 361/400\n",
      "125/125 - 0s - loss: 1.1448e-04 - val_loss: 0.0282\n",
      "Epoch 362/400\n",
      "125/125 - 0s - loss: 1.0673e-04 - val_loss: 0.0278\n",
      "Epoch 363/400\n",
      "125/125 - 0s - loss: 1.0769e-04 - val_loss: 0.0280\n",
      "Epoch 364/400\n",
      "125/125 - 0s - loss: 1.0677e-04 - val_loss: 0.0277\n",
      "Epoch 365/400\n",
      "125/125 - 0s - loss: 1.1172e-04 - val_loss: 0.0277\n",
      "Epoch 366/400\n",
      "125/125 - 0s - loss: 1.0189e-04 - val_loss: 0.0277\n",
      "Epoch 367/400\n",
      "125/125 - 1s - loss: 1.0846e-04 - val_loss: 0.0278\n",
      "Epoch 368/400\n",
      "125/125 - 0s - loss: 1.1085e-04 - val_loss: 0.0281\n",
      "Epoch 369/400\n",
      "125/125 - 0s - loss: 1.0754e-04 - val_loss: 0.0279\n",
      "Epoch 370/400\n",
      "125/125 - 0s - loss: 1.0605e-04 - val_loss: 0.0282\n",
      "Epoch 371/400\n",
      "125/125 - 0s - loss: 1.1246e-04 - val_loss: 0.0281\n",
      "Epoch 372/400\n",
      "125/125 - 1s - loss: 1.0695e-04 - val_loss: 0.0280\n",
      "Epoch 373/400\n",
      "125/125 - 0s - loss: 1.0252e-04 - val_loss: 0.0277\n",
      "Epoch 374/400\n",
      "125/125 - 0s - loss: 1.0610e-04 - val_loss: 0.0279\n",
      "Epoch 375/400\n",
      "125/125 - 0s - loss: 1.0066e-04 - val_loss: 0.0281\n",
      "Epoch 376/400\n",
      "125/125 - 0s - loss: 9.9995e-05 - val_loss: 0.0282\n",
      "Epoch 377/400\n",
      "125/125 - 0s - loss: 1.0212e-04 - val_loss: 0.0282\n",
      "Epoch 378/400\n",
      "125/125 - 0s - loss: 9.8186e-05 - val_loss: 0.0283\n",
      "Epoch 379/400\n",
      "125/125 - 0s - loss: 1.0538e-04 - val_loss: 0.0281\n",
      "Epoch 380/400\n",
      "125/125 - 0s - loss: 9.7130e-05 - val_loss: 0.0282\n",
      "Epoch 381/400\n",
      "125/125 - 6s - loss: 1.0015e-04 - val_loss: 0.0284\n",
      "Epoch 382/400\n",
      "125/125 - 1s - loss: 1.0377e-04 - val_loss: 0.0285\n",
      "Epoch 383/400\n",
      "125/125 - 7s - loss: 9.7172e-05 - val_loss: 0.0282\n",
      "Epoch 384/400\n",
      "125/125 - 6s - loss: 9.9225e-05 - val_loss: 0.0281\n",
      "Epoch 385/400\n",
      "125/125 - 1s - loss: 9.4493e-05 - val_loss: 0.0282\n",
      "Epoch 386/400\n",
      "125/125 - 6s - loss: 9.3603e-05 - val_loss: 0.0282\n",
      "Epoch 387/400\n",
      "125/125 - 1s - loss: 9.1696e-05 - val_loss: 0.0282\n",
      "Epoch 388/400\n",
      "125/125 - 7s - loss: 9.1136e-05 - val_loss: 0.0282\n",
      "Epoch 389/400\n",
      "125/125 - 1s - loss: 9.4468e-05 - val_loss: 0.0279\n",
      "Epoch 390/400\n",
      "125/125 - 6s - loss: 9.5673e-05 - val_loss: 0.0279\n",
      "Epoch 391/400\n",
      "125/125 - 1s - loss: 9.4818e-05 - val_loss: 0.0284\n",
      "Epoch 392/400\n",
      "125/125 - 1s - loss: 1.0099e-04 - val_loss: 0.0279\n",
      "Epoch 393/400\n",
      "125/125 - 1s - loss: 9.5168e-05 - val_loss: 0.0280\n",
      "Epoch 394/400\n",
      "125/125 - 0s - loss: 9.2837e-05 - val_loss: 0.0284\n",
      "Epoch 395/400\n",
      "125/125 - 1s - loss: 9.2811e-05 - val_loss: 0.0283\n",
      "Epoch 396/400\n",
      "125/125 - 1s - loss: 9.2330e-05 - val_loss: 0.0283\n",
      "Epoch 397/400\n",
      "125/125 - 0s - loss: 8.6703e-05 - val_loss: 0.0283\n",
      "Epoch 398/400\n",
      "125/125 - 0s - loss: 8.7535e-05 - val_loss: 0.0282\n",
      "Epoch 399/400\n",
      "125/125 - 0s - loss: 9.0806e-05 - val_loss: 0.0283\n",
      "Epoch 400/400\n",
      "125/125 - 0s - loss: 9.1061e-05 - val_loss: 0.0283\n",
      "Train Loss: 9.106050129048526e-05\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    y_train,\n",
    "    y_train,\n",
    "    epochs=NUM_EPOCHS,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    validation_data=(y_valid, y_valid),\n",
    "    callbacks=callbacks,\n",
    "    verbose=2,\n",
    ")\n",
    "\n",
    "loss = history.history[\"loss\"][-1]\n",
    "print(f\"Train Loss: {loss}\")\n",
    "\n",
    "write_dir = 'HistoryAuto/'\n",
    "model.save('HistoryAuto/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82b855a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_rand_songs(write_dir, rand_vecs):\n",
    "    for i in range(rand_vecs.shape[0]):\n",
    "        x_rand = rand_vecs[i:i+1]\n",
    "        y_song = func([x_rand, 0])[0]\n",
    "        midi.samples_to_midi(y_song[0], write_dir + 'rand' + str(i) + '.mid', 16, 0.25)\n",
    "\n",
    "def make_rand_songs_normalized(write_dir, rand_vecs):\n",
    "    x_enc = np.squeeze(enc.predict(y_orig))\n",
    "\n",
    "    x_mean = np.mean(x_enc, axis=0)\n",
    "    x_cov = np.cov((x_enc - x_mean).T)\n",
    "    _, s, v = np.linalg.svd(x_cov)\n",
    "    e = np.sqrt(s)\n",
    "\n",
    "    print(f\"Means: {x_mean[:6]}\")\n",
    "    print(f\"Evals: {e[:6]} \")\n",
    "\n",
    "    x_vecs = x_mean + np.dot(rand_vecs * e, v)\n",
    "    make_rand_songs(write_dir, x_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e82ea914",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means: [-0.03726133 -0.07928503 -0.15553497 -0.0909754   0.02902214  0.18507527]\n",
      "Evals: [2.85171153 2.25515102 2.13224153 2.06794223 1.96064154 1.84799436] \n"
     ]
    }
   ],
   "source": [
    "y_song = model.predict((y_test_song).reshape(1,16,96,96), batch_size=BATCH_SIZE)\n",
    "\n",
    "midi.samples_to_midi(y_song[0], write_dir + 'test.mid', 16)\n",
    "make_rand_songs_normalized(write_dir, rand_vecs)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9120da6c2d63ded445b1a09e31569bbaba4e2e721b03136355509f1402b65420"
  },
  "kernelspec": {
   "display_name": "Python (IC)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
