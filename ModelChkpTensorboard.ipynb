{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "21519a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "28d4581d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import time \n",
    "\n",
    "from midi_utils import *\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "214e96fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_samples = []\n",
    "\n",
    "# for dirpath, _, filenames in os.walk('OnlyPiano_TPB128'):\n",
    "#     for File in filenames:\n",
    "#         path = os.path.join(dirpath, File)\n",
    "#         mid = mido.MidiFile(path)\n",
    "#         try:\n",
    "#             samples = midi_to_pianoroll(mid)\n",
    "#             all_samples.append(samples)\n",
    "#         except:\n",
    "#             pass\n",
    "# all_samples = np.array(all_samples, dtype=np.uint8)\n",
    "# np.save('samples.npy', all_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1c2c23cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.load('samples.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "11022d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = x[:-28]\n",
    "X_valid = x[-28:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "567c657b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rounded_accuracy(y_true, y_pred):\n",
    "    return tf.keras.metrics.binary_accuracy(tf.round(y_true), tf.round(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d89d144d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "def create_model():\n",
    "    stacked_encoder = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Flatten(input_shape=[128, 512]),\n",
    "        tf.keras.layers.Dense(1024, activation=\"selu\"),\n",
    "        tf.keras.layers.Dense(512, activation=\"selu\"),\n",
    "    ])\n",
    "    stacked_decoder = tf.keras.models.Sequential([\n",
    "        tf.keras.layers.Dense(1024, activation=\"selu\", input_shape=[512]),\n",
    "        tf.keras.layers.Dense(128*512, activation=\"sigmoid\"),\n",
    "        tf.keras.layers.Reshape([128, 512])\n",
    "    ])\n",
    "    stacked_ae = tf.keras.models.Sequential([stacked_encoder, stacked_decoder])\n",
    "    \n",
    "    stacked_ae.compile(loss=\"binary_crossentropy\", optimizer=tf.keras.optimizers.SGD(learning_rate=1.5), metrics=[rounded_accuracy])\n",
    "    \n",
    "    return stacked_ae"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1203622",
   "metadata": {},
   "source": [
    "## Primeiro exemplo de Checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b9e2d18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 58ms/step - loss: -15.2503 - rounded_accuracy: 0.5172 - val_loss: -4.9580 - val_rounded_accuracy: 0.5105\n",
      "\n",
      "Epoch 00001: saving model to training_1\\cp.ckpt\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 23ms/step - loss: -22.9429 - rounded_accuracy: 0.5309 - val_loss: -6.0250 - val_rounded_accuracy: 0.5187\n",
      "\n",
      "Epoch 00002: saving model to training_1\\cp.ckpt\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 22ms/step - loss: -23.2721 - rounded_accuracy: 0.5544 - val_loss: -5.6210 - val_rounded_accuracy: 0.5351\n",
      "\n",
      "Epoch 00003: saving model to training_1\\cp.ckpt\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 23ms/step - loss: -23.5129 - rounded_accuracy: 0.5619 - val_loss: -5.7743 - val_rounded_accuracy: 0.5392\n",
      "\n",
      "Epoch 00004: saving model to training_1\\cp.ckpt\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 22ms/step - loss: -23.2503 - rounded_accuracy: 0.5687 - val_loss: -5.1530 - val_rounded_accuracy: 0.5486\n",
      "\n",
      "Epoch 00005: saving model to training_1\\cp.ckpt\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 22ms/step - loss: -23.1069 - rounded_accuracy: 0.5796 - val_loss: -4.8909 - val_rounded_accuracy: 0.5474\n",
      "\n",
      "Epoch 00006: saving model to training_1\\cp.ckpt\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 22ms/step - loss: -22.9933 - rounded_accuracy: 0.5769 - val_loss: -4.7487 - val_rounded_accuracy: 0.5553\n",
      "\n",
      "Epoch 00007: saving model to training_1\\cp.ckpt\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 25ms/step - loss: -23.0695 - rounded_accuracy: 0.5876 - val_loss: -4.7986 - val_rounded_accuracy: 0.5556\n",
      "\n",
      "Epoch 00008: saving model to training_1\\cp.ckpt\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 27ms/step - loss: -22.9798 - rounded_accuracy: 0.5950 - val_loss: -4.8238 - val_rounded_accuracy: 0.5586\n",
      "\n",
      "Epoch 00009: saving model to training_1\\cp.ckpt\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 23ms/step - loss: -22.8565 - rounded_accuracy: 0.6041 - val_loss: -4.6895 - val_rounded_accuracy: 0.5597\n",
      "\n",
      "Epoch 00010: saving model to training_1\\cp.ckpt\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = 'training_1/cp.ckpt'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_weights_only=True, verbose=1)\n",
    "\n",
    "model = create_model()\n",
    "history = model.fit(X_train, X_train, epochs=10,\n",
    "                    validation_data=(X_valid, X_valid),\n",
    "                    callbacks = [cp_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31f94a4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x23e1d5985e0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.load_weights(checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82212922",
   "metadata": {},
   "source": [
    "## Segundo exemplo de checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ee9dac78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n",
      "\n",
      "Epoch 00005: saving model to training_2\\cp-0005.ckpt\n",
      "\n",
      "Epoch 00010: saving model to training_2\\cp-0010.ckpt\n",
      "\n",
      "Epoch 00015: saving model to training_2\\cp-0015.ckpt\n",
      "\n",
      "Epoch 00020: saving model to training_2\\cp-0020.ckpt\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = 'training_2/cp-{epoch:04d}.ckpt'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path, save_weights_only=True, verbose=1, period = 5)\n",
    "\n",
    "model = create_model()\n",
    "history = model.fit(X_train, X_train, epochs=20,\n",
    "                    validation_data=(X_valid, X_valid),\n",
    "                    callbacks = [cp_callback], verbose =0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95691a42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training_2\\\\cp-0020.ckpt'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "latest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812479bc",
   "metadata": {},
   "source": [
    "## Terceiro Exemplo de checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9d3271a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x23e1d1e2f10>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "model = create_model()\n",
    "model.load_weights('./checkpoints/my_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0c41a45f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique, counts = np.unique(a, return_counts=True)\n",
    "# dict(zip(unique, counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cef45de",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(X_valid)\n",
    "\n",
    "for i in range(10):\n",
    "    mid = pianoroll_to_midi(predict[i])\n",
    "    mid.save(f'generatedSongs/music{i+1}.mid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4402698e",
   "metadata": {},
   "source": [
    "## Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "869ac291",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices(X_train)\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3249c806",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.binary_crossentropy()\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fa407c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('train_accuracy')\n",
    "test_loss = tf.keras.metrics.Mean('test_loss', dtype=tf.float32)\n",
    "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('test_accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bb712791",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, optimizer, x_train):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(x_train, training=True)\n",
    "        loss = loss_object(predictions)\n",
    "    grads = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    train_loss(loss)\n",
    "\n",
    "def test_step(model, x_test, y_test):\n",
    "    predictions = model(x_test)\n",
    "    loss = loss_object(y_test, predictions)\n",
    "\n",
    "    test_loss(loss)\n",
    "    test_accuracy(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b92470fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_time = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "train_log_dir = 'logs/gradient_tape/' + current_time + '/train'\n",
    "test_log_dir = 'logs/gradient_tape/' + current_time + '/test'\n",
    "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
    "test_summary_writer = tf.summary.create_file_writer(test_log_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "394c3516",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model() # reset our model\n",
    "\n",
    "EPOCHS = 5\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for (x_train) in train_dataset:\n",
    "        train_step(model, optimizer, x_train)\n",
    "    with train_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', train_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('accuracy', train_accuracy.result(), step=epoch)\n",
    "\n",
    "    for (x_test, y_test) in test_dataset:\n",
    "        test_step(model, x_test, y_test)\n",
    "    with test_summary_writer.as_default():\n",
    "        tf.summary.scalar('loss', test_loss.result(), step=epoch)\n",
    "        tf.summary.scalar('accuracy', test_accuracy.result(), step=epoch)\n",
    "\n",
    "    template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n",
    "    print (template.format(epoch+1,\n",
    "                         train_loss.result(), \n",
    "                         train_accuracy.result()*100,\n",
    "                         test_loss.result(), \n",
    "                         test_accuracy.result()*100))\n",
    "\n",
    "    # Reset metrics every epoch\n",
    "    train_loss.reset_states()\n",
    "    test_loss.reset_states()\n",
    "    train_accuracy.reset_states()\n",
    "    test_accuracy.reset_states()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8b6cdabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (IC)",
   "language": "python",
   "name": "ic"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
